----------------------
-- RIGHTS AGREEMENT --
----------------------

*header: Rights Agreement

*NOTE* *:* By completing this survey, you are giving us the rights to any responses you give herein. We may use those responses in any way we see fit, and none of your responses will be credited to you. If you cannot agree to these terms, please exit the survey now.

*button: I understand, and I agree to the terms!

------------------
-- INSTRUCTIONS --
------------------

>> failedQuiz = 0

*label: instructions

*header: Instructions

*if: failedQuiz = 1
	*component
		*classes: alert alert-danger
		Uh-oh! You didn't answer at least one of the quiz questions correctly! Please read the instructions again!

Welcome, and thanks for taking this survey! We really appreciate your time and effort!

In this survey, we'll describe to you three *cognitive biases*. Cognitive biases are flaws in your thinking that lead you to misinterpret information from the world around you and to come to inaccurate conclusions. For each cognitive bias, we'll describe the bias to you and then ask you two questions. 

First, we'll ask you to think about a scenario in which you're trying to help a friend or loved one to adopt a new positive habit or pattern of behavior, like going to the gym regularly, giving to charity each month, managing anger, meditating every morning, etc. Then we'll ask you to think about (1) ways that you could help that friend or loved one to /overcome/ the bias so that they can adopt the new habit or behavior, and/or (2) ways that you could ethically /leverage/ the bias to help the person to adopt the new habit or behavior.

For the second question, we'll ask you which of the Ten Conditions for Change that your bias corresponds to. (Don't worry; we'll tell you all about the Ten Conditions for Change when we get to those questions!)

*button: I understand!

-------------
-- EXAMPLE --
-------------

*header: Example

Let's pretend that there's a bias called the *Special Numbers Bias*, and most people experience it. The Special Numbers Bias is a subconscious preference for some numbers and a distaste for other numbers. For example, many people set their TV volume or radio volume to certain numbers, like multiples of 2 or 5. Other people have fear of certain "unlucky" numbers, like 13 or 666, and so will avoid using them whenever possible and will feel a (possibly subconscious) negative "vibe" about the context in which those numbers are presented to them. 

If you were trying to get a friend or loved one to adopt a new positive habit or pattern of behavior, how would you (1) help the person to /overcome/ the Special Numbers Bias in order to adopt the new habit or behavior, and/or (2) ethically /leverage/ the bias to help the person to adopt the new habit or behavior?

Well, you might give an answer like this: 

*html
	<style>
		blockquote {
			margin: 1em 0;
			padding: 1em;
			background-color: rgb(235, 235, 235);
			border-radius: 4px;
			border: 0 !important;
		}

		hr {
			border: 0 !important;
			background-color: rgb(51, 51, 51) !important;
			padding: 1px !important;
			margin: 1em 0 2em 0;
		}
	</style>

	<blockquote>
		<h4>Answer</h4>

		<hr>

		<p>If a friend was trying to adopt the habit of going to the gym every day, I would try to help them to <i>overcome</i> the Special Numbers Bias by:</p>

		<ul>
			<li>trying to convince them that there's nothing special or scary about any particular numbers</li>
			<li>asking them to record daily numbers, like the number of reps they did on weights, the amount of time they ran for on the treadmill, the day of the month, their weight, and their mood or progress to show them that there's ultimately no correlation between positive or negative outcomes and certain numbers</li>
			<li>(if they can't be convinced by the above steps) allowing them to avoid any numbers they feel a negative vibe about, like allowing them to skip going to the gym on the 13th of every month, or allowing them to pick numbers of reps that don't incorporate any numbers they dislike</li>
		</ul>

		<p>I would try to <i>leverage</i> the Special Numbers Bias to help them begin going to the gym by:</p>

		<ul>
			<li>plan workouts that include their favorite numbers, like using numbers of reps that they like, or numbers of minutes on the treadmill that they like, etc.</li>
			<li>speak words of encouragement or praise or giving other kinds of rewards any time they get to a favorite number when doing reps or running on the treadmill or when they work out for a favorite number of days, etc.</li>
		</ul>
	</blockquote>

Once you feel like you understand this example, feel free to continue on to the survey!

*button: I'm ready!

----------
-- QUIZ --
----------

*label: quiz

*page
	*header: Quiz

	Before we let you begin the survey, let's take a quick little quiz to make sure that you understand the instructions.

	*question: What is a /cognitive bias/?
		*answers: [["A cognitive bias is a flaw in your thinking that leads you to misinterpret information from the world around you and to come to an inaccurate conclusion.", "yes"], ["A cognitive bias is a flaw in an argument that invalidates the argument.", "no"], ["A cognitive bias is a new positive habit or pattern of behavior that someone is trying to adopt.", "no"], ["A cognitive bias is a set of instructions for overcoming old, bad habits (caused or maintained by faulty reasoning) and adopting new positive habits.", "no"]]
		*shuffle
		*save: gotQuestion1Right

	*question: What kind of scenario should you imagine after reading about the cognitive bias and before answering the first question?
		*answers: [["I should imagine a scenario in which I'm trying to help a friend or loved one to adopt a new positive habit or pattern of behavior.", "yes"], ["I should imagine a scenario in which I'm taking a survey.", "no"], ["I should imagine a scenario in which I'm meditating every morning.", "no"], ["I should imagine a scenario in which I have no cognitive biases at all.", "no"]]
		*shuffle
		*save: gotQuestion2Right

*if: gotQuestion1Right = "no" or gotQuestion2Right = "no"
	>> failedQuiz = 1
	*goto: instructions

*header: Good job!

You answered the quiz questions correctly! Now it's time to begin the survey!

*button: Okay!

----------------
-- RANDOMIZER --
----------------

>> counter = 1
>> previousRandomNumbers = []
>> final = {}

*label: randomizer

*service: Random Number API
	*path: /get-random-number?min=0&max=182&type=int
	*method: GET
	*success
		>> randomNumber = it["result"]
	*error
		ERROR: {it}

>> i = 1

*while: i <= previousRandomNumbers.size
	*if: previousRandomNumbers[i] = randomNumber
		*goto: randomizer

	>> i = i + 1

>> previousRandomNumbers.add(randomNumber)

*if: randomNumber = 0
	*group
		>> bias = {"name" -> "Anchoring Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>A person's expectation about one thing is affected by something he/she saw, heard, or thought before. This occurs when people rely too heavily on a specific piece of information to govern their thought-process. <br><br>In one study, an audience was asked to write the last two digits of their social security number and consider whether they would pay this number of dollars for items such as wine, chocolate, and computer equipment, the value of which they did not know. They were then asked to bid for these items. The result was that the audience members with higher two-digit numbers would submit bids that were between 60 percent and 120 percent higher than those with the lower social security numbers. Put simply, the higher the (social security) number in mind, the higher the bid. The social security numbers had become their &quot;anchors&quot;.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Anchoring", "groupName" -> "AnchoringBias"}

*if: randomNumber = 1
	*group
		>> bias = {"name" -> "Attentional Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>Some information or evidence may hold a disproportionate amount of a person's attention because of that person's environment, and emotionally stimulating events/items within it.<br><br>In studies using the dot-probe paradigm, patients who suffered from chronic ailments such as anxiety were more likely to focus on information or stimuli representing their concerns (in the case of anxiety: worried facial expressions).<br><br> A 'within-subjects' bias occurs when an individual displays greater bias toward one type of information (e.g., painful faces) when compared to different types of information (e.g., neutral faces). Alternatively, a 'between-subjects' bias, occurs when one group of participants displays greater bias than another group of participants (e.g., chronic pain patients showed greater bias towards painful expressions than did healthy control participants).</div><br>", "source" -> "http://en.wikipedia.org/wiki/Attentional_Bias", "groupName" -> "AttentionalBias"}

*if: randomNumber = 2
	*group
		>> bias = {"name" -> "Bandwagon Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The Bandwagon Effect is the tendency to do or believe things because many other people do or believe the same. It is a phenomenon observed primarily within the fields of microeconomics, political science, and behaviorism. <br><br>In Solomon Asch's Conformity Experiments, students who participated in &quot;vision tests&quot; were more likely to answer questions about the length of a line incorrectly if others in the same room (in this case, confederates of Asch) who answered the question first provided incorrect answers. Similarly, if at least one of the confederates gave the correct answer, the students became far more likely to also give the correct answer.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Asch_conformity_experiments", "groupName" -> "BandwagonEffect"}

*if: randomNumber = 3
	*group
		>> bias = {"name" -> "Bias Blind Spot", "content" -> "<div class='text' style='font-size: 16.8px;'>This describes the tendency to see oneself as less biased than others. <br><br>In Pronin's study at Princeton University, several biases were explained to subjects. When subsequently asked how biased they themselves were, subjects rated themselves as being much less prone to the biases described than the average person is prone.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Bias_blind_spot", "groupName" -> "BiasBlindSpot"}

*if: randomNumber = 4
	*group
		>> bias = {"name" -> "Choice-supportive Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>This is the tendency to remember one's choices as better than they actually were. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways. For example, one predictable way that memories of choices are distorted is that positive aspects tend to be remembered as part of the chosen option, regardless of whether they originally part of that option, and negative aspects tend to be remembered as part of rejected options. This may affect a person's regret or approval of past decisions, and may also influence future decision making.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Choice-supportive_bias", "groupName" -> "ChoicesupportiveBias"}

*if: randomNumber = 5
	*group
		>> bias = {"name" -> "Confirmation Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>A tendency for people to favor information that confirms their preconceptions or hypotheses regardless of whether the information is true. <br><br>Experiments have repeatedly found that people tend to test hypotheses in a one-sided way: by searching for evidence consistent with the hypothesis they have formed at a given time. Confirmation biases are not limited to the collection of evidence. Although two individuals may have the same information, the way they interpret it can be biased. Even if someone has sought and interpreted evidence in a neutral manner, he or she may still remember it selectively to reinforce his/her expectations. So, the Confirmation Bias may operate at three different stages: when gathering evidence, when analyzing the evidence, or when remembering the evidence.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Confirmation_bias", "groupName" -> "ConfirmationBias"}

*if: randomNumber = 6
	*group
		>> bias = {"name" -> "Congruence Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to test hypotheses exclusively through direct testing. Congruence Bias occurs due to people's over-reliance on direct testing of a given hypothesis and on a neglect of indirect testing. For example, in an experiment, a subject will test his own (usually) naive hypothesis again and again instead of trying to disprove it.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Congruence_bias", "groupName" -> "CongruenceBias"}

*if: randomNumber = 7
	*group
		>> bias = {"name" -> "Contrast Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>A perception that is stronger or weaker, relative to objective measurement or typical experience, due to a prior or simultaneous exposure to a stimulus of less or greater value in the same dimension.<br><br>For example, as John Locke noted, lukewarm water may feel extremely hot or cold, depending on the temperature of your hand when you feel it. Similarly, a heavy weight is perceived as heavier than normal when felt at the same time as a lighter weight.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Contrast_effect", "groupName" -> "ContrastEffect"}

*if: randomNumber = 8
	*group
		>> bias = {"name" -> "Denomination Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The Denomination Effect is a theoretical cognitive bias relating to currency: people are less likely to spend larger bills than their equivalent value in smaller bills.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Denomination_effect", "groupName" -> "DenominationEffect"}

*if: randomNumber = 9
	*group
		>> bias = {"name" -> "Distinction Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to view two options as more dissimilar when evaluating them simultaneously than when evaluating them separately. <br><br>Research shows that options presented simultaneously are evaluated differently than the same options presented separately. For example, when televisions are displayed next to each other on the sales floor, the difference in quality between two very similar, high-quality televisions may appear great. A consumer may pay a much higher price for the higher-quality television, even though the difference in quality is imperceptible when the televisions are viewed in isolation.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Distinction_bias", "groupName" -> "DistinctionBias"}

*if: randomNumber = 10
	*group
		>> bias = {"name" -> "Endowment Effect (aka Divestiture Aversion)", "content" -> "<div class='text' style='font-size: 16.8px;'>People place a higher value on objects that they own than on objects they do not. <br><br>In one experiment, people demanded a higher price for a coffee mug that had been given to them, but put a lower price on one they did not yet own. The Endowment Effect was described as inconsistent with standard economic theory, which asserts that a person's willingness to pay for a good should be equal to their willingness to accept compensation to be deprived of the good.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Endowment_effect", "groupName" -> "EndowmentEffectAkaDivestitureAversion"}

*if: randomNumber = 11
	*group
		>> bias = {"name" -> "Experimenter's or Expectation Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>This is the tendency for experimenters to believe, certify, and publish data that agree with their expectations for the outcome of an experiment, and to disbelieve, discard, or downgrade the corresponding weightings for data that appear to conflict with those expectations. In review of biases in clinical studies, David Sackett states that biases can occur in any one of seven stages of research:<br><br> 1. reading up on the field,<br> 2. specifying and selecting the study sample,<br> 3. executing the experimental maneuver (or exposure),<br> 4. measuring exposures and outcomes,<br> 5. analyzing the data,<br> 6. interpreting the analysis,<br> 7. publishing the results.<br><br>The inability of a human being to be objective is the ultimate source of this bias.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Expectation_bias", "groupName" -> "ExperimentersOrExpectationBias"}

*if: randomNumber = 12
	*group
		>> bias = {"name" -> "Focusing Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The Focusing Effect (or Focusing Illusion) is a cognitive bias that occurs when people place too much importance on one aspect of an event (especially, the aspect they happen to be thinking about at the moment). This error causes inaccuracy when predicting how useful a potential outcome will be.<br><br>In one experiment, when predicting relative happiness of Californians to themselves, Midwesterners predicted that Californians were more happy overall, because they were focusing on positive factors like the weather, while ignoring negative factors like crime rate.<br><br>The Focusing Effect is different from but related to the Attentional Bias: the Attentional Bias entails specific features of the environment, causing one to pay undue attention to certain things, whereas the Focusing Effect entails the mere process of thinking about something causing that thing to seem more important than it really is. One manifestation of the focusing effect can be summarized as, &quot;Things aren't as important as you think they are when you're thinking about them.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/Focusing_effect", "groupName" -> "FocusingEffect"}

*if: randomNumber = 13
	*group
		>> bias = {"name" -> "Framing Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>Presenting the same option in different formats can alter people's decisions. Specifically, individuals have a tendency to make inconsistent choices, depending on whether the question is framed to concentrate on losses or gains. <br><br>A set of experiments on framing indicated that different phrasing affected participants' responses to a question about a disease prevention strategy. Two options were presented to subjects, both describing the same statistical outcome, but one focused on the number of deaths, while the other focused on number of lives. Participants were much more likely to choose the option that &quot;saved&quot; lives.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Framing_effect_%28psychology%29", "groupName" -> "FramingEffect"}

*if: randomNumber = 14
	*group
		>> bias = {"name" -> "Hostile Media Effect (Disconfirmation Bias)", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to see a media report as being biased due to one's own strong partisan views. <br><br>In the first major study of this phenomenon, pro-Palestinian students and pro-Israeli students were shown the same news filmstrips pertaining to the then-recent (1982) Sabra and Shatila massacre of Palestinian refugees by Christian Lebanese militia fighters in Beirut during the Lebanese Civil War. On a number of objective measures, both sides found that these identical news clips were slanted in favor of the other side. This effect is interesting to psychologists because it appears to be a reversal of the otherwise pervasive effects of confirmation bias. I.e., in this area, people seem to pay more attention to information that contradicts rather than supports their existing views. <br><br>This is an example of Disconfirmation Bias.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Hostile_media_effect", "groupName" -> "HostileMediaEffectDisconfirmationBias"}

*if: randomNumber = 15
	*group
		>> bias = {"name" -> "Hyperbolic Discounting", "content" -> "<div class='text' style='font-size: 16.8px;'>Given two similar rewards, humans show a preference for one that arrives sooner rather than later. Humans are said to discount the value of the later reward, by a factor that increases with the length of the delay. <br><br>The standard experiment used to reveal a test subject's hyperbolic discounting curve is to compare short-term preferences with long-term preferences. For instance: &quot;Would you prefer a dollar today or three dollars tomorrow?&quot; or &quot;Would you prefer a dollar in one year or three dollars in one year and one day?&quot; For certain ranges of offerings, a significant fraction of subjects will take the lesser amount today, but will gladly wait one extra day in a year in order to receive the higher amount instead.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Hyperbolic_discounting", "groupName" -> "HyperbolicDiscounting"}

*if: randomNumber = 16
	*group
		>> bias = {"name" -> "Illusion of Control", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to overestimate one's degree of influence over external events. The illusion is more common in familiar situations, and in situations where the person knows the desired outcome. The illusion can also be altered by emotional state. For example, the illusion is weaker for depressed individuals and is stronger when individuals have an emotional need to control the outcome. <br><br>To investigate perceptions of control, experimenters may ask people about hypothetical situations, for example the likelihood of their involvement in a motor vehicle accident. On average, drivers regard accidents as much less likely in &quot;high-control&quot; situations, such as when they are driving, than in &quot;low-control&quot; situations, such as when they are in the passenger seat. They also rate a high-control accident, such as driving into the car in front, as much less likely than a low-control accident such as being hit from behind by another driver.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Illusion_of_control", "groupName" -> "IllusionOfControl"}

*if: randomNumber = 17
	*group
		>> bias = {"name" -> "Impact Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to overestimate the length or the intensity of the impact of future feeling states. For example, people seem to think that if disaster strikes, it will take longer to recover emotionally than it actually does. Conversely, if a happy event occurs, people overestimate how long they will emotionally benefit from it.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Impact_bias", "groupName" -> "ImpactBias"}

*if: randomNumber = 18
	*group
		>> bias = {"name" -> "Information Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>Involves e.g., distorted evaluation of information. Information Bias occurs due to people's curiosity and confusion of goals when trying to choose a course of action. An example of Information Bias is believing that the more information that can be acquired to make a decision, the better, even if that extra information is irrelevant for the decision. Examples of Information Bias are prevalent in medical diagnoses. Subjects in experiments concerning medical diagnostic problems show an information bias in which they seek information that is unnecessary in deciding the course of treatment.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Information_bias_%28psychology%29", "groupName" -> "InformationBias"}

*if: randomNumber = 19
	*group
		>> bias = {"name" -> "Irrational Escalation (aka Escalation of Commitment) / Sunk Cost Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The phenomenon where people justify increased investment in a decision based on the cumulative prior investment, despite new evidence suggesting that the cost (starting today) of continuing the decision outweighs the expected benefit. <br><br>The term has been used to describe the United States commitment to military conflicts including Vietnam in the 1960s - 1970s and in Iraq in the 2000s, where dollars already spent and lives already lost &quot;justify&quot; continued involvement. (&quot;We've already come this far...&quot;)</div><br>", "source" -> "http://en.wikipedia.org/wiki/Irrational_escalation", "groupName" -> "IrrationalEscalationAkaEscalationOfCommitmentSunkCostFallacy"}

*if: randomNumber = 20
	*group
		>> bias = {"name" -> "Loss Aversion", "content" -> "<div class='text' style='font-size: 16.8px;'>Loss aversion refers to people's tendency to strongly prefer avoiding losses to acquiring gains. Some studies suggest that losses are twice as powerful, psychologically, as gains. Whether a transaction is framed as a loss or a gain is very important: would you rather get a $5 discount (win), or avoid a $5 surcharge (loss)? The same change in price framed differently has a significant effect on consumer behavior. In other words, losses have a more profound effect on us than does a gain of the same value. Recent studies have questioned the existence of loss aversion. One found that loss aversion does not exist in small payoff magnitudes. Another found that loss aversion is more likely to affect a person in competitive situations. This is related to the Endowment Effect, and was once thought to be an consequence of it.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Loss_aversion", "groupName" -> "LossAversion"}

*if: randomNumber = 21
	*group
		>> bias = {"name" -> "Mere Exposure Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to express undue liking for things merely because of familiarity with them. <br><br>Charles Goetzinger conducted an experiment using the Mere Exposure Effect on his class at Oregon State University. Goetzinger had a student come to class wearing a large black bag with only his feet visible. That student (student A) sat on a table in the back of the classroom. Goetzinger's experiment was to observe if the students would treat Student A in accordance with the Mere Exposure Effect. His hypothesis was confirmed. The students in the class first treated Student A with hostility, which over time turned into curiosity, and eventually friendship. This experiment confirms (Zajonc's) Mere Exposure Effect: by simply presenting the student wearing the black bag over and over again to the other students, their attitudes were changed.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Mere_exposure_effect", "groupName" -> "MereExposureEffect"}

*if: randomNumber = 22
	*group
		>> bias = {"name" -> "Money Illusion", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to concentrate on the nominal (face) value of money rather than its value in terms of purchasing power. Money Illusion can also influence people's perceptions of outcomes. Experiments have shown that people generally perceive a 2% cut in nominal income as unfair, but see a 2% rise in nominal income where there is 4% inflation as fair, despite them being almost rational equivalents.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Money_illusion", "groupName" -> "MoneyIllusion"}

*if: randomNumber = 23
	*group
		>> bias = {"name" -> "Moral Credential Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>An individual's track record as an egalitarian individual can establish a subconscious ethical certification, endorsement, or license within that individual which will increase their likelihood of making less egalitarian decisions later. For example, individuals who had the opportunity to recruit a woman or an African American in one setting were more likely to later say, in a different setting, that a job would be better suited for a man or a Caucasian.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Moral_credential", "groupName" -> "MoralCredentialEffect"}

*if: randomNumber = 24
	*group
		>> bias = {"name" -> "Negativity Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>A psychological phenomenon by which humans pay more attention to and give more weight to negative rather than positive experiences or other kinds of information. For example, when given a piece of positive information and a piece of negative information about a stranger, people's judgment of the stranger will be negative, rather than neutral (assuming the two pieces of information are not severely imbalanced).</div><br>", "source" -> "http://en.wikipedia.org/wiki/Negativity_bias", "groupName" -> "NegativityBias"}

*if: randomNumber = 25
	*group
		>> bias = {"name" -> "Neglect of Probability", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to completely disregard probability when making a decision under uncertainty. With this bias, the actor completely disregards probability when making a decision, instead of using probability incorrectly. <br><br>In one example of near-total neglect of probability, Rottenstreich and Hsee (2001) found that the typical subject was willing to pay $10 to avoid a 99% chance of a painful electric shock, and $7 to avoid a 1% chance of the same shock. (They suggest that probability is more likely to be neglected when the outcomes are emotion arousing.) The subject disregards probability in making his decision by treating each possible outcome as equal in his reasoning.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Neglect_of_probability", "groupName" -> "NeglectOfProbability"}

*if: randomNumber = 26
	*group
		>> bias = {"name" -> "Normalcy Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>A mental state people enter when facing a disaster which causes them to underestimate both the possibility of a disaster occurring and its possible effects. An assumption is made in the case of the Normalcy Bias that since a disaster never has occurred, it never will occur. It also results in a person's inability to cope with a disaster once it does occur. People with a normalcy bias have difficulties reacting to something they have not experienced before. People also tend to interpret warnings in the most optimistic way possible, seizing on any ambiguities to infer a less serious situation. The normalcy bias often results in unnecessary deaths in disaster situations. <br><br>One example took place in New Orleans before Hurricane Katrina. Some examples of normalcy bias include inadequate government and citizen preparation, the denial that the levees could fail, and thousands of people's refusals to evacuate.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Normalcy_bias", "groupName" -> "NormalcyBias"}

*if: randomNumber = 27
	*group
		>> bias = {"name" -> "Omission Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to judge harmful actions as worse, or less moral, than equally harmful omissions (inactions). It is contentious whether this represents a systematic error in thinking, or whether this is supported by a substantive moral theory. Spranca, Minsk, and Baron extended the omission bias to judgments of morality of choices. <br><br>In one scenario, John, a tennis player, would be facing a tough opponent the next day in a decisive match. John knows that his opponent is allergic to a food substance. Subjects were presented with two conditions: John recommends the food containing the allergen to hurt his opponent's performance, or the opponent himself orders the allergenic food, and John says nothing. A majority of people judged that John's action of recommending the allergenic food as being more immoral than John's inaction of not informing the opponent of the allergenic substance.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Omission_bias", "groupName" -> "OmissionBias"}

*if: randomNumber = 28
	*group
		>> bias = {"name" -> "Outcome Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>One will often judge a past decision by its ultimate outcome instead of by the quality of the decision at the time it was made, given what was known at that time. This is an error because no decision maker ever knows whether or not a calculated risk will turn out for the best. Individuals whose judgments are influenced by Outcome Bias are seemingly holding decision makers responsible for events beyond their control. The reason why an individual makes this mistake is that he or she will incorporate presently available information when evaluating a past decision. <br><br>Baron and Hershey (1988) presented subjects with hypothetical situations in order to test this. One such example involved a surgeon deciding whether or not to do a risky surgery on a patient. The surgery had a known probability of success. Subjects were presented with either a good or bad outcome (in this case living or dying), and asked to rate the quality of the surgeon's pre-operation decision. Those presented with bad outcomes rated the decision worse than those who were presented with good outcomes.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Outcome_bias", "groupName" -> "OutcomeBias"}

*if: randomNumber = 29
	*group
		>> bias = {"name" -> "Planning Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The Planning Fallacy is a tendency for people and organizations to underestimate how long they will need to complete a task, even when they have past experience of similar tasks overrunning. The bias only affects predictions about one's own tasks; when uninvolved observers predict task completion times, they show a pessimistic bias, overestimating the time taken. In 2003, Lovallo and Kahneman proposed an expanded definition as the tendency to underestimate the time, costs, and risks of future actions and at the same time overestimate the benefits of the same actions. <br><br>In a 1994 study, 37 psychology students were asked to estimate how long it would take to finish their senior theses. The average estimate was 33.9 days. They also estimated how long it would take &quot;if everything went as well as it possibly could&quot; (averaging 27.4 days) and &quot;if everything went as poorly as it possibly could&quot; (averaging 48.6 days). The average actual completion time was 55.5 days, with only about 30% of the students completing their thesis in the amount of time they predicted.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Planning_fallacy", "groupName" -> "PlanningFallacy"}

*if: randomNumber = 30
	*group
		>> bias = {"name" -> "Post-purchase Rationalization", "content" -> "<div class='text' style='font-size: 16.8px;'>A special case of Choice-supportive Bias, someone who purchases an expensive product or service overlooks any faults or defects in order to justify their purchase. <br><br>For example, a consumer cannot decide between two popular video game consoles, A and B, but in the end decides to purchase product A on the basis that many of their peers also own this console. After purchasing it, he finds out that product A has a minimal amount of games and product B has more titles that the consumer would like to play. However, he does not wish to feel that he made the wrong decision, and so will attempt to convince himself and his peers that product A is better than product B.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Post-purchase_rationalization", "groupName" -> "PostpurchaseRationalization"}

*if: randomNumber = 31
	*group
		>> bias = {"name" -> "Pseudo-certainty Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>A person's tendency to perceive an outcome as certain while in fact it is uncertain, or the tendency to make risk-averse choices if the expected outcome is positive, but make risk-seeking choices to avoid negative outcomes. For example, when considering multi-stage decisions, subjects may assume the first stage will go in their favor and only focus on the probability of the second stage of the process. A subject's evaluation of outcomes in a previous decision stage is discarded when making a choice in subsequent stages.<br><br>FYI - There is a very long and specific math-oriented example</div><br>", "source" -> "http://en.wikipedia.org/wiki/Pseudocertainty_effect", "groupName" -> "PseudocertaintyEffect"}

*if: randomNumber = 32
	*group
		>> bias = {"name" -> "Reactance", "content" -> "<div class='text' style='font-size: 16.8px;'>An emotional reaction in direct contradiction to rules or regulations that threaten or eliminate specific behavioral freedoms. Reactance can cause a person to adopt or strengthen a view or attitude that is contrary to what was intended, and also increases resistance to persuasion. <br><br>An example of such behavior can be observed when an individual engages in a prohibited activity in order to deliberately taunt the authority who prohibits it, regardless of the utility or disutility that the activity confers. There are four important elements to reactance theory: perceived freedom, threat to freedom, reactance, and restoration of freedom. Freedom is not an abstract consideration, but rather a feeling associated with real behaviors, including actions, emotions, and attitudes. <br><br>One study concluded that one way to increase the activity of a threatened freedom is to censor it, or provide a threatening message toward the activity. In turn a &quot;boomerang effect&quot; occurs, in which people choose forbidden alternatives. This study also shows that social influence has better results when it does not threaten one's core freedoms. Two concepts revealed in this study are that a communicator may be able to increase the positive force toward compliance by increasing his or her credibility, and that increasing the positive communication force and decreasing the negative communication force simultaneously should increase compliance.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Reactance_%28psychology%29", "groupName" -> "Reactance"}

*if: randomNumber = 33
	*group
		>> bias = {"name" -> "Restraint Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to overestimate one's own ability to show restraint in the face of temptation.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Restraint_bias", "groupName" -> "RestraintBias"}

*if: randomNumber = 34
	*group
		>> bias = {"name" -> "Selective Perception", "content" -> "<div class='text' style='font-size: 16.8px;'>Selective Perception may refer to any number of cognitive biases in psychology related to the way expectations affect perception. For instance, several studies have shown that students who were told that they were consuming alcoholic beverages (which in fact were non-alcoholic) perceived themselves as being &quot;drunk&quot;, exhibited fewer physiological symptoms of social stress, and drove a simulated car similarly to other subjects who had actually consumed alcohol. The result is somewhat similar to the Placebo Effect.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Selective_perception", "groupName" -> "SelectivePerception"}

*if: randomNumber = 35
	*group
		>> bias = {"name" -> "Semmelweis Reflex", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to reject new evidence that contradicts an established paradigm. There is some uncertainty regarding the origin and generally accepted use of the expression. It refers to Ignaz Semmelweis, who discovered that child-bed fever mortality rates could be reduced ten-fold if doctors would wash their hands (we would now say disinfect) with a chlorine solution between having contact with infected patients and non-infected patients. His hand-washing suggestions were rejected by his contemporaries.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Semmelweis_reflex", "groupName" -> "SemmelweisReflex"}

*if: randomNumber = 36
	*group
		>> bias = {"name" -> "Social Comparison Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>When making hiring decisions, people tend to favor potential candidates who don't compete with their own particular strengths.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Social_comparison_bias", "groupName" -> "SocialComparisonBias"}

*if: randomNumber = 37
	*group
		>> bias = {"name" -> "Status Quo Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>A cognitive bias for the status quo; in other words, people tend not to change an established behavior unless the incentive to change is compelling. The US states of New Jersey and Pennsylvania inadvertently ran a real life experiment providing evidence of the Status Quo Bias in the early 1990s. As part of Tort law reform programs, citizens were offered two options for their automotive insurance: an expensive option giving them full right to sue, and a less expensive option with restricted rights to sue. In New Jersey the cheaper option was the default and most citizens selected it, while only a minority chose it in Pennsylvania where the more expensive option was the default. Similar effects have been shown for contributions to retirement plans, choice of internet privacy policies and the decision to become an organ donor.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Status_quo_bias", "groupName" -> "StatusQuoBias"}

*if: randomNumber = 38
	*group
		>> bias = {"name" -> "Unit Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to want to finish a given unit of a task or an item. Strong effects on the consumption of food in particular.</div><br>", "source" -> "http://en.wikipedia.org/wiki/List_of_cognitive_biases", "groupName" -> "UnitBias"}

*if: randomNumber = 39
	*group
		>> bias = {"name" -> "Wishful Thinking", "content" -> "<div class='text' style='font-size: 16.8px;'>The formation of beliefs and making decisions according to what might be pleasing to imagine instead of by appealing to evidence, rationality or reality. Studies have consistently shown that, holding all else equal, subjects will predict positive outcomes to be more likely than negative outcomes. This logical fallacy has the form &quot;I wish that P is true/false, therefore P is true/false.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/Wishful_thinking", "groupName" -> "WishfulThinking"}

*if: randomNumber = 40
	*group
		>> bias = {"name" -> "Zero-risk Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>Zero-risk Bias occurs when individuals value complete elimination of a risk, however small, to a reduction in a greater risk. That is, individuals may prefer small benefits that are certain to large ones that are uncertain, regardless of the size of the &quot;certain&quot; benefit.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Zero-risk_bias", "groupName" -> "ZeroriskBias"}

*if: randomNumber = 41
	*group
		>> bias = {"name" -> "Ambiguity Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>A cognitive bias where decision making is affected by a lack of information, or &quot;ambiguity&quot;. The effect implies that people tend to select options for which the probability of a favorable outcome is known, instead of an option for which the probability of a favorable outcome is unknown. <br><br>FYI - The only example is a lengthy probability problem</div><br>", "source" -> "http://en.wikipedia.org/wiki/Ambiguity_effect", "groupName" -> "AmbiguityEffect"}

*if: randomNumber = 42
	*group
		>> bias = {"name" -> "Availability Cascade", "content" -> "<div class='text' style='font-size: 16.8px;'>A self-reinforcing cycle that explains the development of certain kinds of collective beliefs. A novel idea or insight (usually one that seems to explain a complex process in a simple or straightforward manner) gains rapid currency in the popular discourse because of its very simplicity and apparent insightfulness.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Availability_cascade", "groupName" -> "AvailabilityCascade"}

*if: randomNumber = 43
	*group
		>> bias = {"name" -> "Availability Heuristic", "content" -> "<div class='text' style='font-size: 16.8px;'>A phenomenon (which can result in a cognitive bias) in which people predict the frequency of an event, or a proportion within a population, based on how easily an example can be brought to mind. <br><br>For example, when asked to rate the probability of a variety of causes of death, people tend to rate more &quot;newsworthy&quot; events as more likely because they can more readily recall an example from memory. For example, in the USA, people may rate the chance of death by homicide higher than the chance of death by stomach cancer, even though death by stomach cancer is five times higher than death by homicide.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Availability_heuristic", "groupName" -> "AvailabilityHeuristic"}

*if: randomNumber = 44
	*group
		>> bias = {"name" -> "Base Rate Neglect", "content" -> "<div class='text' style='font-size: 16.8px;'>Base Rate Neglect, or Base Rate Fallacy or Bias, is an error that occurs when the conditional probability of some hypothesis H, given some evidence E, is assessed without taking into account the &quot;base rate&quot; or &quot;prior probability&quot; of H and the total probability of evidence E. <br><br>In some experiments, students were asked to estimate the grade point averages (GPAs) of hypothetical students. When given relevant statistics about GPA distribution, students tended to ignore them if given descriptive information about the particular student, even if the new descriptive information was obviously of little or no relevance to school performance. <br><br>Psychologists attempted to explain this finding in terms of the Representativeness Heuristic. Others have argued that some attributional biases like the fundamental attribution error are instances of the Base Rate Fallacy: people under-utilize &quot;consensus information&quot; (the &quot;base rate&quot;) about how others behaved in similar situations and instead prefer simpler dispositional attributions.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Base_rate_fallacy", "groupName" -> "BaseRateNeglect"}

*if: randomNumber = 45
	*group
		>> bias = {"name" -> "Belief Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>An effect where someone's evaluation of the logical strength of an argument is affected by whether or not the conclusion is believable. <br><br>In a series of experiments, subjects were presented with deductive arguments (in each of which a series of premises and a conclusion are given) and asked to indicate if each conclusion necessarily follows from the premises given. In other words, the subjects are asked to make an evaluation of logical validity. The subjects, however, exhibited belief bias when they rejected valid arguments with unbelievable conclusions, and endorsed invalid arguments with believable conclusions. It seems that instead of following directions and assessing logical validity, the subjects based their assessments on personal beliefs.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Belief_bias", "groupName" -> "BeliefBias"}

*if: randomNumber = 46
	*group
		>> bias = {"name" -> "Clustering Illusion", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to see patterns where actually none exist. Thomas Gilovich found that most people saw non-random sequences in the string of random data: OXXXOXXXOXXOOOXOOXXOO.<br></div><br>", "source" -> "http://en.wikipedia.org/wiki/Clustering_illusion", "groupName" -> "ClusteringIllusion"}

*if: randomNumber = 47
	*group
		>> bias = {"name" -> "Conjunction Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>A logical fallacy that occurs when it is assumed that specific conditions are more probable than a single general one. In one experiment, subjects were presented with the following scenario: Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations.<br><br> Which is more probable?<br><br> 1. Linda is a bank teller.<br> 2. Linda is a bank teller and is active in the feminist movement.<br><br>85% of those asked chose option 2. However the probability of two events occurring together (in &quot;conjunction&quot;) is always less than or equal to the probability of either one occurring alone. But in another study, the question is rephrased in a more concrete format, and participants are likely to get the answer right. This demonstrates that it may be a result of poor word choice, rather than bias, that causes subjects to create unrealistic associations.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Conjunction_fallacy", "groupName" -> "ConjunctionFallacy"}

*if: randomNumber = 48
	*group
		>> bias = {"name" -> "Forward Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to create models based on past data which are validated only against that past data.</div><br>", "source" -> "http://visayanatheists.wordpress.com/2011/05/12/list-of-cognitive-biases/", "groupName" -> "ForwardBias"}

*if: randomNumber = 49
	*group
		>> bias = {"name" -> "Gambler's Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The belief that if deviations from expected behavior are observed in repeated independent trials of some random process, future deviations in the opposite direction are then more likely. While the probability of a run of five heads is only 1‚ÅÑ32 = 0.03125, it is only that before the coin is first tossed. After the first four tosses the results are no longer unknown, so their probabilities are 1. Reasoning that it is more likely that the next toss will be a tail than a head due to the past tosses, that a run of luck in the past somehow influences the odds in the future, is the fallacy.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Gambler%27s_fallacy", "groupName" -> "GamblersFallacy"}

*if: randomNumber = 50
	*group
		>> bias = {"name" -> "Hindsight Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>Hindsight Bias, also known as the &quot;knew-it-all-along&quot; effect, is the inclination to see events that have already occurred as being more predictable than they were before they took place. This bias is recognized with the expression &quot;hindsight is 20/20&quot;.<br><br>In one study, participants were given a short story with four possible outcomes. They are told that one of the outcomes is the &quot;true&quot; outcome, and are then asked to assign the likelihood of each particular outcome. Participants frequently assign a higher likelihood of occurrence to whichever outcome they have been told is true.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Hindsight_bias", "groupName" -> "HindsightBias"}

*if: randomNumber = 51
	*group
		>> bias = {"name" -> "Illusory Correlation", "content" -> "<div class='text' style='font-size: 16.8px;'>The phenomenon of seeing the relationship one expects in a set of data even when no such relationship exists. <br><br>This bias can be caused by, among other things, an event that stands out as unique. Variables capture the attention simply because they are novel or deviant. This is one way stereotypes form and endure. David Hamilton and Terrence Rose (1980) found that stereotypes can lead people to expect certain groups and traits to fit together, and they overestimate the frequency of when these correlations actually occur. People overestimate the core association between variables such as stereotyped groups and stereotypical behavior.<br><br>Rupert Brown and Amanda Smith (1989) tested the hypothesis by conducting a study involving the academic staff at a British university. The results revealed that the staff had overestimated the number of female seniority staff and underestimated the number of male senior staff. This reflected that the academic staff inaccurately viewed the relationship between gender and seniority, showing that illusory correlations can exist in everyday situations.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Illusory_correlation", "groupName" -> "IllusoryCorrelation"}

*if: randomNumber = 52
	*group
		>> bias = {"name" -> "Observer-expectancy Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>This is when a researcher (or individual) expects a given result and therefore subconsciously manipulates an experiment or misinterprets data in order to find it. <br><br>An example of the Observer-expectancy Effect is demonstrated in music back-masking, in which hidden verbal messages are said to be audible when a recording is played backwards. Often when a song is played backwards, a listener will fail to notice the &quot;hidden&quot; lyrics until they are explicitly pointed out, after which they are obvious.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Observer-expectancy_effect", "groupName" -> "ObserverexpectancyEffect"}

*if: randomNumber = 53
	*group
		>> bias = {"name" -> "Optimism Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The demonstrated tendency for people to be overly optimistic about the outcome of planned actions. This includes over-estimating the likelihood of positive events and under-estimating the likelihood of negative events.<br><br>Armor and Taylor review a number of studies that have found optimism bias in different kinds of judgment. These include:<br><br> - Second-year MBA students overestimated the number of job offers they would receive and their starting salary;<br> - Students overestimated the scores they would achieve on exams;<br> - Almost all newlyweds in a US study expected their marriage to last a lifetime, even while aware of divorce statistics;<br> - Professional financial analysts consistently overestimated corporate earnings;<br> - Most smokers believe they are less at risk of developing smoking-related diseases than others who smoke.<br><br>Companies have exploited this bias by increasing interest rates to punitive rates for any late payment, knowing that overconfidence causes many people to grossly underestimate their odds of making a payment late.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Optimism_bias", "groupName" -> "OptimismBias"}

*if: randomNumber = 54
	*group
		>> bias = {"name" -> "Ostrich Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The Ostrich Effect is the tendency to avoid apparently risky (financial) situations by pretending they do not exist. The name comes from the common (but false) legend that ostriches bury their heads in the sand to avoid danger.<br><br>Research by Loewenstein and Duane Seppi determined that people in Scandinavia looked up the value of their investments 50% to 80% less often during bad markets.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Ostrich_effect", "groupName" -> "OstrichEffect"}

*if: randomNumber = 55
	*group
		>> bias = {"name" -> "Overconfidence Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>Excessive confidence in one's own answers to questions. The Overconfidence Effect is one of the most important and well-studied cognitive biases in psychology and behavioral economics. Overconfidence has been studied in three different ways:<br><br> 1. Overestimation of one's performance, ability, level of control, or rate of work; <br> 2. An inflated belief that one is better than others, or over-placement; and<br> 3. An excessive belief in the truth and accuracy of one‚Äôs beliefs, or over-precision.<br><br>One is example is shown in a spelling task, where subjects were correct about 80% of the time when they were &quot;100% certain.&quot; Put another way, the error rate was 20% when subjects expected it to be 0%.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Overconfidence_effect", "groupName" -> "OverconfidenceEffect"}

*if: randomNumber = 56
	*group
		>> bias = {"name" -> "Positive Outcome Bias / Valence Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>A person's tendency to overestimate the probability of a favorable outcome in a given situation.<br><br>In one experiment, all other things being equal, participants assigned a higher probability to picking a card that had a smiling face on its reverse side than one which had a frowning face.<br><br>Also known as the Valence Effect. The outcome of valence effects may be called &quot;wishful thinking&quot;.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Valence_effect", "groupName" -> "PositiveOutcomeBiasValenceEffect"}

*if: randomNumber = 57
	*group
		>> bias = {"name" -> "Pareidolia", "content" -> "<div class='text' style='font-size: 16.8px;'>A vague and random stimulus (often an image or sound) is perceived as significant, e.g., seeing images of animals or faces in clouds, the man in the moon, and hearing hidden messages on records played in reverse.<br><br>Pareidolia is why we find a &quot;face&quot; when we look at two dots and a line arranged inside of a circle.<br><br>Carl Sagan hypothesized that as a survival technique, human beings are &quot;hard-wired&quot; from birth to identify the human face. This allows people to use only minimal details to recognize faces from a distance and in poor visibility, but can also lead them to interpret random images or patterns of light and shade as being faces. The evolutionary advantages of being able to identify friend from foe with split-second accuracy are numerous. For example, prehistoric (and even modern) men and women who accidentally identify an enemy as a friend could face deadly consequences for this mistake. This is only one among many evolutionary pressures responsible for the development of the modern facial recognition capability of modern humans.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Pareidolia", "groupName" -> "Pareidolia"}

*if: randomNumber = 58
	*group
		>> bias = {"name" -> "Pessimism Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency for some people, especially those suffering from depression, to overestimate the likelihood of negative things happening to them.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Pessimism_bias", "groupName" -> "PessimismBias"}

*if: randomNumber = 59
	*group
		>> bias = {"name" -> "Primacy Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to weigh or remember initial events or information more than subsequent events or information. For example, a subject who reads a sufficiently long list of words is more likely to remember words toward the beginning than words in the middle (though words at the end of the list may be even more memorable).</div><br>", "source" -> "http://en.wikipedia.org/wiki/Primacy_effect#Primacy_effect", "groupName" -> "PrimacyEffect"}

*if: randomNumber = 60
	*group
		>> bias = {"name" -> "Recency Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to weigh recent events more than earlier events. There are two models that may explain this effect. The Duo Store Model suggests that items stored in short term memory are more readily accessible, and therefore the most recent information a person has reviewed will be most available and weighed most heavily. The Single Store Model suggests that either recent information is most distinct or that it is most closely associated with the &quot;test&quot; where the information is needed, and therefore most recent information is more easily accessible.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Recency_effect#Recency_effect", "groupName" -> "RecencyEffect"}

*if: randomNumber = 61
	*group
		>> bias = {"name" -> "Disregard of Regression toward the Mean", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to expect extreme performance to continue, despite the fact that it is most likely for performance to be closer to average overall as it continues.<br><br>When things happen to deviate from the mean by chance, you assume the abnormal behavior will continue.<br><br>&quot;&quot;When his pain got worse, he went to a doctor, after which the pain subsided somewhat. Therefore, he benefited from the doctor's treatment.&quot;&quot;<br> <br>This assumes the pain would have continued without the doctors treatment.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Regression_toward_the_mean", "groupName" -> "DisregardOfRegressionTowardTheMean"}

*if: randomNumber = 62
	*group
		>> bias = {"name" -> "Stereotyping", "content" -> "<div class='text' style='font-size: 16.8px;'>Expecting a member of a group to have certain characteristics without having actual information about that individual.<br><br>The term &quot;stereotype&quot; derives from the Greek words œÉœÑŒµœÅŒµœåœÇ (stereos), meaning &quot;firm, solid&quot;, and œÑœçœÄŒøœÇ (typos), meaning &quot;impression,&quot; hence: &quot;solid impression&quot;. It was originally a term used in the world of printing to describe a duplicate impression of an original typographical element, used for printing instead of the original.<br><br>There are many theories about why individuals tend to stereotype. One theory is that stereotyping is the most convenient way to sort information - grouping large numbers of people and experiences together. It could also be the case that one's childhood experiences are primary in the creation of stereotypes, and these stereotypes learned in childhood are self-perpetuating, growing stronger as an individual ages. A third theory focuses on an individual's need to feel good about him or herself. If I am part of Group A, and Group A is &quot;right&quot; about everything, then it is best for my self esteem to lump other individuals into separate, inferior groups.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Stereotyping", "groupName" -> "Stereotyping"}

*if: randomNumber = 63
	*group
		>> bias = {"name" -> "Subadditivity", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to judge the probability of the whole to be less than the sum of the probabilities of the component parts.<br><br>For instance, subjects in one experiment judged that the probability of death from cancer in the United States was 18%, the probability from heart attack was 22%, and the probability of death from &quot;other natural causes&quot; was 33%. Other participants judged that the probability of death from a natural cause was 58%. Natural causes are made up precisely of cancer, heart attack, and &quot;other natural causes,&quot; however, the sum of the latter three probabilities was 73%, and not 58%. According to Tversky and Koehler (1994) this kind of result is observed consistently.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Subadditivity_effect", "groupName" -> "Subadditivity"}

*if: randomNumber = 64
	*group
		>> bias = {"name" -> "Subjective Validation", "content" -> "<div class='text' style='font-size: 16.8px;'>The perception that something is true if a subject's belief demands it to be true. Also assigns perceived connections between coincidences. In other words, a person whose opinion is affected by Subjective Validation will perceive two unrelated events (i.e., a coincidence) to be related because their personal belief demands that they be related.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Subjective_validation", "groupName" -> "SubjectiveValidation"}

*if: randomNumber = 65
	*group
		>> bias = {"name" -> "Well-travelled Road Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The Well-travelled Road Effect is a cognitive bias in which travellers will estimate the time taken to traverse routes differently depending on their familiarity with the route. Frequently travelled routes are assessed as taking a shorter time than unfamiliar routes.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Well_travelled_road_effect", "groupName" -> "WelltravelledRoadEffect"}

*if: randomNumber = 66
	*group
		>> bias = {"name" -> "Actor-observer Asymmetry", "content" -> "<div class='text' style='font-size: 16.8px;'>Actors, those assessing their own behavior, tend to emphasize the influence of the situation and the situation's effect on their behavior, and under-emphasize the influence of their own character. When observing others' actions, observers tend to emphasize aspects of behavior and personality, and how those characteristics lead to a behavior, rather than the situation's influence.<br><br>This has been demonstrated in studies by differentiating between actors' and observers' explanations in the following way: people's explanations are separated into theoretically meaningful distinctions (e.g., reasons vs. causal history of reason explanations). Then responses can be effectively categorized, and the differences emerge.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Actor%E2%80%93observer_bias", "groupName" -> "ActorobserverAsymmetry"}

*if: randomNumber = 67
	*group
		>> bias = {"name" -> "Dunning‚ÄìKruger Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The unskilled suffer from illusory superiority, rating their ability as above average (much higher than it actually is), while the highly skilled underrate their own abilities, suffering from illusory inferiority, as they assume others have a similar understanding. As Kruger and Dunning noted, &quot;the miscalibration of the incompetent stems from an error about the self, whereas the miscalibration of the highly competent stems from an error about others&quot;.<br><br>Dunning and Kruger concluded, &quot;across four studies, the authors found that participants scoring in the bottom quartile on tests of humor, grammar, and logic grossly overestimated their test performance and ability. Although test scores put them in the 12th percentile, they estimated themselves to be in the 62nd.&quot; Meanwhile, people with true ability tended to underestimate their relative competence. Roughly, participants who found tasks to be relatively easy erroneously assumed, to some extent, that the tasks must also be easy for others.<br><br>Studies on the Dunning‚ÄìKruger Effect tend to focus on American test subjects. Similar studies on European subjects show marked muting of the effect; studies on some East Asian subjects suggest that something like the opposite of the Dunning‚ÄìKruger effect operates on self-assessment and motivation to improve.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect", "groupName" -> "DunningkrugerEffect"}

*if: randomNumber = 68
	*group
		>> bias = {"name" -> "Egocentric Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>This occurs when people claim more personal responsibility for the results of a joint action than an outside observer would credit them. This is unique because they will take an unfair share of credit for both positive and negative results.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Egocentric_bias", "groupName" -> "EgocentricBias"}

*if: randomNumber = 69
	*group
		>> bias = {"name" -> "Forer (or Barnum) Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to believe that a description of your own personality is accurate despite the fact that it is vague enough to apply to a wide range of people. <br><br>In 1948, psychologist Bertram R. Forer gave a personality test to his students. He told his students they were each receiving a unique personality analysis that was based on the test's results and to rate their analysis on a scale of 0 (very poor) to 5 (excellent) on how well it applied to themselves. In reality, each received the same analysis. On average, the rating was 4.26, but only after the ratings were turned in was it revealed that each student had received identical copies assembled by Forer from various horoscopes.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Forer_effect", "groupName" -> "ForerOrBarnumEffect"}

*if: randomNumber = 70
	*group
		>> bias = {"name" -> "False Consensus Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>A person tends to overestimate how much other people agree with him or her. There is a tendency for people to assume that their own opinions, beliefs, preferences, values, and habits are 'normal', and that others also think the same way that they think. This can either lead a person to believe that his opinions are shared by the majority, or, even if he is aware that they are not shared by the majority, he will overestimate the number of people with whom he shares the opinion. Additionally, when confronted with evidence that a consensus does not exist, people often assume that those who do not agree with them are defective in some way.<br><br>This bias can be traced back to primarily two roots. According to social comparison, individuals evaluate their thoughts and attitudes based on other people, and often look towards others to find a &quot;norm&quot; by which they may judge themselves. The problem, though, is that people are often unable to accurately perceive the social norm and the actual attitudes of others. Due to projection, a person may see aspects of himself in others, whether accurate, imagined, or exaggerated.</div><br>", "source" -> "http://en.wikipedia.org/wiki/False_consensus_effect", "groupName" -> "FalseConsensusEffect"}

*if: randomNumber = 71
	*group
		>> bias = {"name" -> "Fundamental Attribution Error", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency for people to over-emphasize personality-based explanations for behaviors observed in others while under-emphasizing the role and power of situational influences on the same behavior. Similar to Actor-observer Bias, but in this case the focus is on a person's interpretation of others' actions, rather than of one's own actions.<br><br>Jones and Harris hypothesized that people would attribute apparently freely-chosen behaviors to disposition, and apparently chance-directed behaviors to situation. The hypothesis was confounded by the Fundamental Attribution Error. Subjects read pro- and anti-Fidel Castro essays, and were then asked to rate the pro-Castro attitudes of the writers. When the subjects believed that the writers freely chose the positions they took (for or against Castro), they naturally rated the people who spoke in favor of Castro as having a more positive attitude towards Castro. However, contradicting Jones's and Harris's initial hypothesis, when the subjects were told that the writers' positions were determined by a coin toss, they still rated writers who spoke in favor of Castro as having, on average, a more positive attitude towards Castro than did those who spoke against him. In other words, the subjects were unable to see the influence of the situational constraints placed upon the writers; they could not refrain from attributing sincere belief to the writers.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Fundamental_attribution_error", "groupName" -> "FundamentalAttributionError"}

*if: randomNumber = 72
	*group
		>> bias = {"name" -> "Halo Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>The perception of one trait (i.e. a characteristic of a person or object) is influenced by the perception of another trait (or several traits) of that person or object. An example would be judging a good-looking person as more intelligent.<br><br>In a psychology study published in 1920, Thorndike asked commanding officers to rate their soldiers; he found high cross-correlation between all positive and all negative traits. People seem not to think of other individuals in mixed terms; instead we seem to see each person as roughly good or roughly bad across all categories of measurement.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Halo_effect", "groupName" -> "HaloEffect"}

*if: randomNumber = 73
	*group
		>> bias = {"name" -> "Illusion of Asymmetric Insight", "content" -> "<div class='text' style='font-size: 16.8px;'>People perceive their knowledge of their peers to surpass their peers' knowledge of them. Furthermore, a group of people often assumes that they know more about other groups than other groups know about them. The source for this bias seems to stem from the fact that observed behaviors of others are more revealing than one's own similar behaviors.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Illusion_of_asymmetric_insight", "groupName" -> "IllusionOfAsymmetricInsight"}

*if: randomNumber = 74
	*group
		>> bias = {"name" -> "Illusion of Transparency", "content" -> "<div class='text' style='font-size: 16.8px;'>A tendency for people to overestimate the degree to which their personal mental state is known by others. Another manifestation of the Illusion of Transparency (sometimes called the Observer's Illusion of Transparency) is a tendency for people to overestimate how well they understand others' personal mental states.<br><br>Initial anxiety in a public speaking situation can cause stress that, because of the Illusion of Transparency, the speaker may feel is evident to the listeners. This mistaken perception can cause the speaker to compensate, which he or she then feels is even more obvious to the crowd, and the stress increases in a feedback loop. Awareness of the limits of others' perceptions of one's mental state can help break the cycle and reduce speech anxiety.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Illusion_of_transparency", "groupName" -> "IllusionOfTransparency"}

*if: randomNumber = 75
	*group
		>> bias = {"name" -> "Illusory Superiority", "content" -> "<div class='text' style='font-size: 16.8px;'>Overestimating one's desirable qualities, and underestimating undesirable qualities, relative to other people. (Also known as &quot;Lake Wobegon Effect,&quot; &quot;Better-than-average Effect,&quot; or &quot;Superiority Bias&quot;). <br><br>In Kruger and Dunning's experiments, participants were given specific tasks (such as logic problems, grammar, and determining whether or not jokes were funny), and were asked to evaluate their performance on these tasks relative to the rest of the group, enabling a direct comparison of their actual and perceived performance. Results were divided into four groups, depending on actual performance. It was found that all four groups evaluated their performance as above average, meaning that the lowest-scoring group (the bottom 25%) showed a very large Illusory Superiority Bias. The researchers attributed this to the fact that the individuals who were worst at performing the tasks were also worst at recognizing skill in those tasks. This was supported by the fact that, given training, the worst subjects improved their estimate of their rank as well as getting better at the tasks.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Illusory_superiority", "groupName" -> "IllusorySuperiority"}

*if: randomNumber = 76
	*group
		>> bias = {"name" -> "In-group Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency for people to give preferential treatment to others they perceive to be members of their own groups.<br><br>The need to improve self esteem may be one cause of this bias: individuals will find a reason, no matter how insignificant, to prove to themselves why their group is superior. By having a more positive impression of individuals in the in-group, individuals are able to boost their own self-esteem as members of that group.<br><br>Robert Cialdini and his research team looked at the number of university T-shirts being worn on college campuses following either a win or loss at the football game. Not surprisingly, the Monday after a win there were more T-shirts being worn, on average, than following a loss.<br><br>The bias may lead to inter-group aggression, competition, and prejudice.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Ingroup_bias", "groupName" -> "IngroupBias"}

*if: randomNumber = 77
	*group
		>> bias = {"name" -> "Just-world Phenomenon", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency for people to want to believe that the world is fundamentally just. As a result, when they witness an otherwise inexplicable injustice, they rationalize it by searching for things that the victim might have done to deserve it, often at the expense of blaming victims for things that were not, objectively, their fault.<br><br>One cause of this phenomenon may be the need to protect one's own sense of invulnerability. They want to believe that if the potential victim avoids the behaviors of the past victims, then they themselves will remain safe.<br><br>In one study, female and male subjects were told two versions of a story about an interaction between a woman and a man. Both variations were exactly the same, except one ending was that the man raped the woman, and in the other he proposed marriage. In both conditions, both female and male subjects viewed the woman's (identical) actions as inevitably leading to the (very different) results.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Just-world_phenomenon", "groupName" -> "JustworldPhenomenon"}

*if: randomNumber = 78
	*group
		>> bias = {"name" -> "Moral Luck", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency for people to ascribe greater or lesser moral standing based on the outcome of an event rather than on the intention. For example, if two drivers run two different red lights, and, all else being equal, one of them hits a person who was crossing the street while the other gets only a traffic ticket, we want to say that the driver who hit a person is more morally corrupt. Both drivers committed the same offense, but under different circumstances.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Moral_luck", "groupName" -> "MoralLuck"}

*if: randomNumber = 79
	*group
		>> bias = {"name" -> "Out-group Homogeneity Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>One perceives out-group members as being more similar to one another than are in-group members. The notion is that &quot;they are alike; we are diverse.&quot; <br><br>This bias was found to be unrelated to the number of group and non-group members individuals knew. For example, the Out-group Homogeneity Bias was found between groups such as &quot;men&quot; and &quot;women,&quot; despite the fact that members of each group interact with one another frequently.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Outgroup_homogeneity_bias", "groupName" -> "OutgroupHomogeneityBias"}

*if: randomNumber = 80
	*group
		>> bias = {"name" -> "Projection Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>A psychological defense mechanism where a person subconsciously denies his or her own attributes, thoughts, and emotions, which he or she then ascribes to the outside world, usually to another person or other people.<br><br>In one example posed by Sigmund Freud, a person might have thoughts of infidelity with respect to a spouse or other partner. Instead of dealing with these undesirable thoughts consciously, the subject unconsciously projects these feelings onto the other person, and begins to think that the other has thoughts of infidelity and that the other may be having an affair.<br><br>Projection can also be a means of justifying certain actions that would normally be found atrocious or heinous. This often means projecting false accusations, information, etc. for the sole purpose of maintaining a self-created illusion about one's own subconscious actions or feelings.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Projection_bias", "groupName" -> "ProjectionBias"}

*if: randomNumber = 81
	*group
		>> bias = {"name" -> "Self-serving Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>Occurs when people attribute their successes to internal or personal factors, but attribute their failures to situational factors beyond their control. The Self-serving Bias can be seen in the common human tendency to take credit for success but to deny responsibility for failure. <br><br>One example of Self-serving Bias can be found in the workplace. Victims of serious occupational accidents tend to attribute their accidents to external factors, whereas their coworkers and management tend to attribute the accidents to the victims' own actions.<br><br>There are several possible causes of this bias. People are motivated to protect their self-esteem; they may be attempting to protect their reputation by advertising successes and shifting blame for failures publicly, regardless of their true understanding of the situation. Additionally, success may be more readily available to memory than failure.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Self-serving_bias", "groupName" -> "SelfservingBias"}

*if: randomNumber = 82
	*group
		>> bias = {"name" -> "System Justification", "content" -> "<div class='text' style='font-size: 16.8px;'>A scientific theory within social psychology that proposes that people have a motivation to defend and bolster the status quo, i.e., to see it as good, legitimate, and desirable.<br><br>Early SJT (Situational Judgment Tests) research focused on compensatory stereotypes. Experiments suggested that the widespread endorsement of stereotypes such as &quot;poor but happy&quot; or &quot;rich but miserable&quot; exist to balance out the gap between those of low and high socioeconomic status. Later work suggested that these compensatory stereotypes are preferred by leftists while rightists prefer non-complimentary stereotypes such as &quot;poor and dishonest&quot; or &quot;rich and honest&quot;, which rationalize inequality rather than compensate for it.<br><br>This differs from the Status Quo Bias because it is predominately motivational, rather than cognitive. It is considered to be motivational because its effects are exacerbated when people are under psychological threat, or when they feel their outcomes are especially dependent on the system that is being justified.</div><br>", "source" -> "http://en.wikipedia.org/wiki/System_justification", "groupName" -> "SystemJustification"}

*if: randomNumber = 83
	*group
		>> bias = {"name" -> "Ultimate Attribution Error", "content" -> "<div class='text' style='font-size: 16.8px;'>This is a bias that people commonly have toward members of an out-group. Similar to the Fundamental Attribution Error, in this error a person is likely to make an internal attribution to an entire group instead of the individuals within the group. For example, they may view negative acts committed by out-group members as a stable trait of the out-group, and positive acts committed by out-group members as exceptions to normal behavior. It is considered to be one of the roots of prejudice.<br><br>In his 1976 demonstration, Birt Duncan asked White participants to watch a video of a man shoving another man. One video had a Caucasian male shoving another Caucasian male and a second video had an African American male shoving a Caucasian male. When the participants watched the first video they concluded that the Caucasian male doing the shoving was attributed to having fun (a situational factor), but when they watched the second video they attributed the African American‚Äôs behavior to an aggressive personality (Duncan, 1979). The results of Duncan's study demonstrates that ultimate attribution error is more likely to occur when there are negative associations with members of an out-group due to previous conflict or certain situations that were experienced (Whitley & Kite, 2010).</div><br>", "source" -> "http://en.wikipedia.org/wiki/Ultimate_attribution_error", "groupName" -> "UltimateAttributionError"}

*if: randomNumber = 84
	*group
		>> bias = {"name" -> "Trait Ascription Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency for people to view themselves as relatively variable in terms of personality, behavior and mood while viewing others as much more predictable. This may be because our own internal states are much more observable and available to us than those of others.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Trait_ascription_bias", "groupName" -> "TraitAscriptionBias"}

*if: randomNumber = 85
	*group
		>> bias = {"name" -> "Inoculation Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>When we hear bad arguments (that we know are bad) in favor of a hypothesis, we may end up believing that hypothesis less, even though we have not necessarily heard any of the good arguments in favor of the hypothesis. It seems to us that if the bad arguments for a hypothesis are wrong, the hypothesis is likely to be false, even though how likely something is to be true hinges on the best arguments for it, not the worst.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Inoculation_theory", "groupName" -> "InoculationEffect"}

*if: randomNumber = 86
	*group
		>> bias = {"name" -> "Backtracking Effect", "content" -> "<div class='text' style='font-size: 16.8px;'>People are less happy doing things that involve undoing what they did previously than spending the same amount of time doing extra work that does not involve backtracking. <br><br>This is related to Trial and Error. For example, consider coming cross a fork in a road. You decide to take route A instead of route B. Halfway down the path, you realize you are going the wrong way and need to take route B. Backtracking can also occur when solving puzzles, such as Sudoku or crossword puzzles.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Backtracking", "groupName" -> "BacktrackingEffect"}

*if: randomNumber = 87
	*group
		>> bias = {"name" -> "Precision/Accuracy Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>People believe that numbers that are stated more precisely (e.g. 75.1259) are more accurate than numbers that are not (e.g. 75). While precision (e.g. lots of decimal points) is necessary for very high levels of accuracy, precision does not necessarily imply accuracy, and when calculators or computers are used to compute quantities, high precision numbers are trivially easy to produce.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Precision_bias", "groupName" -> "PrecisionaccuracyBias"}

*if: randomNumber = 88
	*group
		>> bias = {"name" -> "Handedness Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>Our tendency to prefer objects (or attribute better qualities to them) when they are presented on the strong side of our bodies (the right side for right handed people, and the left side for left handed people).</div><br>", "source" -> "http://www.sott.net/articles/show/241582-Different-Bodies-Different-Minds-The-Handedness-Bias", "groupName" -> "HandednessBias"}

*if: randomNumber = 89
	*group
		>> bias = {"name" -> "Fallacy of Difference", "content" -> "<div class='text' style='font-size: 16.8px;'>The tendency to attribute the outcome of a situation to whatever traits make that situation most unusual.<br><br>For instance, if you're friend and his wife get a divorce, you might assume that it was due to the fact that they were in an open marriage (a trait that made their marriage stand out as unusual), rather than taking into account the fact that it is common for relationships of all types to end.</div><br>", "source" -> "http://rationallyspeaking.blogspot.com/2011/07/fallacy-of-difference-in-science-and.html", "groupName" -> "FallacyOfDifference"}

*if: randomNumber = 90
	*group
		>> bias = {"name" -> "Thinking in Categories / Binary Thinking", "content" -> "<div class='text' style='font-size: 16.8px;'>Lumping things into simple categories, like &quot;good and bad&quot;, &quot;right and wrong&quot;, &quot;easy and hard&quot; rather than viewing things as being on a continuum.</div><br>", "source" -> "http://www.haas.berkeley.edu/groups/finance/cat3.pdf", "groupName" -> "ThinkingInCategoriesBinaryThinking"}

*if: randomNumber = 91
	*group
		>> bias = {"name" -> "Temporal Discounting", "content" -> "<div class='text' style='font-size: 16.8px;'>This is similar to Hyperbolic Discounting in that subjects prefer benefits or rewards sooner rather than later, which may lead to Dynamic Inconsistency: how each different self of a decision-maker may have different preferences over current and future choices. For example, a decision maker holds the view that &quot;now&quot; has especially high value compared to any future time. This Temporal Discounting is a tendency to give greater value to rewards as they move away from their temporal horizons and towards the &quot;now&quot;. For instance, a nicotine-deprived smoker may highly value a cigarette available any time in the next 6 hours but assign little or no value to a cigarette available in 6 months.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Dynamic_inconsistency", "groupName" -> "TemporalDiscounting"}

*if: randomNumber = 92
	*group
		>> bias = {"name" -> "Disjunction Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The use of the Representativeness Heuristic may lead to a Disjunction Fallacy. From probability theory, the disjunction of two events is at least as likely as either of the events individually. For example, the probability of being either a physics or a biology major is at least as likely as being a physics major, if not more likely. However, when a personality description (data) seems to be very representative of a physics major (e.g., pocket protector) over a biology major, people judge that it is more likely for this person to be a physics major than a natural sciences major (which is a superset of physics).<br><br>Further evidence that the Representativeness Heuristic may be causal to the Disjunction Fallacy comes from Bar-Hillel and Neter (1986). They found that people judge a person who is highly representative of being a statistics major (e.g., highly intelligent, does math competitions) as being more likely to be a statistics major than a social sciences major (superset of statistics), but they do not think that he is more likely to be a Hebrew language major than a humanities major (superset of Hebrew language). Thus, only when the person seems highly representative of a category is that category judged as more probable than its superordinate category. These incorrect appraisals remained even in the face of losing real money in bets on probabilities.</div><br>", "source" -> "http://en.wikipedia.org/wiki/representativeness_heuristic", "groupName" -> "DisjunctionFallacy"}

*if: randomNumber = 93
	*group
		>> bias = {"name" -> "Ad Hoc Rescue", "content" -> "<div class='text' style='font-size: 16.8px;'>Trying to save a cherished belief by repeatedly revising the argument to explain away problems.<br><br>&quot;But apart from better sanitation, medicine, education, irrigation, public health, roads, a freshwater system and public order.. What have the Romans done for us?&quot;</div><br>", "source" -> "", "groupName" -> "AdHocRescue"}

*if: randomNumber = 94
	*group
		>> bias = {"name" -> "Ad Hominem", "content" -> "<div class='text' style='font-size: 16.8px;'>Bypassing the argument by launching an irrelevant attack on the person and not their claim. <br><br>&quot;Anyone that says we should build the Ground Zero Mosque is an American-hating liberal.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AdHominem"}

*if: randomNumber = 95
	*group
		>> bias = {"name" -> "Anecdotal evidence fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Discounting evidence arrived at by systematic search or testing in favor of a few firsthand stories.<br><br>&quot;I'm going to carry on smoking. My grandfather smoked 40 a day until he died aged 90.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AnecdotalEvidenceFallacy"}

*if: randomNumber = 96
	*group
		>> bias = {"name" -> "Appeal to Probability Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Possibly P. Therefore, P.<br><br>Assumes that because something could happen, it is inevitable that it will happen.<br>&quot;There are many hackers that spread worms through the internet. Therefore, if you use the internet without a firewall, it is inevitable that you will be hacked sooner or later.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/appeal_to_probability", "groupName" -> "AppealToProbabilityFallacy"}

*if: randomNumber = 97
	*group
		>> bias = {"name" -> "Argument from Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>If P, then Q. <br>P is a fallacious argument. <br>Therefore, Q is false.<br><br>Analyzing an argument and inferring that, since it contains a fallacy, its conclusion must be false.<br>&quot;Our opponents have falsely argued that abortion should be legal because it reduces crime rates. Now that this claim has been proven false, we can conclude that abortion should be made illegal.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/argument_from_fallacy", "groupName" -> "ArgumentFromFallacy"}

*if: randomNumber = 98
	*group
		>> bias = {"name" -> "Affirming a Disjunct Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>A or B. <br>A. <br>Therefore not B.<br><br>The fallacy lies in concluding that one disjunct must be false because the other disjunct is true; in fact they may both be true. This results from &quot;or&quot; being defined inclusively rather than exclusively.<br><br>&quot;American politicians either believe in democracy or in capitalism. Since that politician believes in democracy, he must not believe in capitalism.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/affirming_a_disjunct", "groupName" -> "AffirmingADisjunctFallacy"}

*if: randomNumber = 99
	*group
		>> bias = {"name" -> "Affirming the Consequent Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>If P, then Q. <br>Q. <br>Therefore P.<br><br>Assuming that if P implies Q then Q implies P<br><br>&quot;If I have the flu, then I have a sore throat. I have a sore throat. Therefore, I have the flu.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/affirming_the_consequent", "groupName" -> "AffirmingTheConsequentFallacy"}

*if: randomNumber = 100
	*group
		>> bias = {"name" -> "Denying the Antecedent Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>If P, then Q. <br>Not P. <br>Therefore, not Q.<br><br>Assuming that if P implies Q, then not P implies not Q.<br><br>If Queen Elizabeth is an American citizen, then she is a human being.<br>Queen Elizabeth is not an American citizen.<br>Therefore, Queen Elizabeth is not a human being.</div><br>", "source" -> "http://en.wikipedia.org/wiki/denying_the_antecedent", "groupName" -> "DenyingTheAntecedentFallacy"}

*if: randomNumber = 101
	*group
		>> bias = {"name" -> "Affirmative Conclusion from a Negative Premise Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>A is not a subset of B. <br>B is not a subset of C. <br>Therefore A is a subset of C.<br><br>&quot;We don't read that trash. <br>People who read that trash don't appreciate real literature. <br>Therefore, we appreciate real literature.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/affirmative_conclusion_from_a_negative_premise", "groupName" -> "AffirmativeConclusionFromANegativePremiseFallacy"}

*if: randomNumber = 102
	*group
		>> bias = {"name" -> "Illicit Major Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>All A are B. <br>No C are A. <br>Therefore, no C are B.<br><br>&quot;Christians are good, and atheists are not Christians. Therefore atheists are not good.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/illicit_major", "groupName" -> "IllicitMajorFallacy"}

*if: randomNumber = 103
	*group
		>> bias = {"name" -> "Illicit Minor Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>All A are B. <br>All A are C. <br>Therefore, all B are C.<br><br>&quot;All men are lovers, and all men are haters. So all haters are also lovers.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/illicit_minor", "groupName" -> "IllicitMinorFallacy"}

*if: randomNumber = 104
	*group
		>> bias = {"name" -> "Fallacy of the Undistributed Middle", "content" -> "<div class='text' style='font-size: 16.8px;'>All Zs are Bs. <br>Y is a B. <br>So Y is a Z.<br><br>&quot;All students carry backpacks, and my grandfather carries a backpack, so my grandfather is a student.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/fallacy_of_the_undistributed_middle", "groupName" -> "FallacyOfTheUndistributedMiddle"}

*if: randomNumber = 105
	*group
		>> bias = {"name" -> "Argument from Ignorance Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Asserts that a proposition is necessarily true because it has not been proven false (or vice versa).<br><br>&quot;We know that quantum mechanics is a true theory because every attempt to test it has failed to find evidence against the theory.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/argument_from_ignorance", "groupName" -> "ArgumentFromIgnoranceFallacy"}

*if: randomNumber = 106
	*group
		>> bias = {"name" -> "Appeal to Incredulity Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Because a claim sounds unbelievable, it must not be true.<br><br>The eye is an incredibly complex biomechanical machine with thousands of interlocking parts. How could that exist without an intelligent designer?</div><br>", "source" -> "rhetological", "groupName" -> "AppealToIncredulityFallacy"}

*if: randomNumber = 107
	*group
		>> bias = {"name" -> "Appeal to Money Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Supposing that, if someone is rich or something is expensive, then it affects the truth of the claim.<br><br>&quot;If it costs more, it must be better&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AppealToMoneyFallacy"}

*if: randomNumber = 108
	*group
		>> bias = {"name" -> "Appeal to Spite Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Dismissing a claim by appealing to personal bias against the claimant.<br><br>Don't you just hate how those rich Liberal Hollywood actors go on TV to promote their agendas?</div><br>", "source" -> "rhetological", "groupName" -> "AppealToSpiteFallacy"}

*if: randomNumber = 109
	*group
		>> bias = {"name" -> "Appeal to Tradition Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Claiming something is true because it's (apparently) always been that way.<br><br>Marriage is the union between man and women. Therefore gay marriage is wrong.</div><br>", "source" -> "rhetological", "groupName" -> "AppealToTraditionFallacy"}

*if: randomNumber = 110
	*group
		>> bias = {"name" -> "Appeal to Wishful Thinking", "content" -> "<div class='text' style='font-size: 16.8px;'>Suggesting a claim is true or false just because you strongly hope it is.<br><br>&quot;The President wouldn't lie. He's our leader and a good American&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AppealToWishfulThinking"}

*if: randomNumber = 111
	*group
		>> bias = {"name" -> "Begging the Question Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The proposition to be proven is assumed implicitly or explicitly in the premise. Or the premise is actually stronger and more controversial than the claim itself that is being debated.<br><br>&quot;Killing innocent people is always wrong. The death penalty will inevitably lead to innocent people dying, so the death penalty is wrong.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/begging_the_question", "groupName" -> "BeggingTheQuestionFallacy"}

*if: randomNumber = 112
	*group
		>> bias = {"name" -> "Biased generalizing", "content" -> "<div class='text' style='font-size: 16.8px;'>Generalizing from an unrepresentative sample to increase the strength of your argument<br><br>&quot;Our website poll found that 90% of internet users oppose online piracy laws.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "BiasedGeneralizing"}

*if: randomNumber = 113
	*group
		>> bias = {"name" -> "Burden of Proof Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'> I don't need to prove my claim is true - you must prove it is false.<br><br>&quot;I maintain long-term solar cycles are the cause of global warming. Show me I'm wrong&quot;</div><br>", "source" -> "rhetological", "groupName" -> "BurdenOfProofFallacy"}

*if: randomNumber = 114
	*group
		>> bias = {"name" -> "Correlation Implies Causation Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assumes that correlation between two variables automatically implies that one causes the other.</div><br>", "source" -> "http://en.wikipedia.org/wiki/correlation_does_not_imply_causation", "groupName" -> "CorrelationImpliesCausationFallacy"}

*if: randomNumber = 115
	*group
		>> bias = {"name" -> "Circumstantial Ad Hominem", "content" -> "<div class='text' style='font-size: 16.8px;'>Stating a claim isn't credible only because of the advocate's interest in their claim.<br><br>&quot;A study into the health risks of mobile phone involved mobile phone companies. Therefore, the study cannot be trusted.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "CircumstantialAdHominem"}

*if: randomNumber = 116
	*group
		>> bias = {"name" -> "Division fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that characteristics or beliefs of a group automatically apply to any individual member. Similar to ecological fallacy.<br><br>&quot;Many Conservatives wish to ban gay marriage, discredit climate change, and deny evolution. Therefore all conservatives are homophobic, anti-enviroment creationists.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "DivisionFallacy"}

*if: randomNumber = 117
	*group
		>> bias = {"name" -> "Ecological Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Inferences about the nature of specific individuals are based solely upon aggregate statistics collected for the group to which those individuals belong. This fallacy assumes that individual members of a group have the average characteristics of the group at large.<br><br>&quot;Of course you can kick her ass. She is a woman.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/ecological_fallacy", "groupName" -> "EcologicalFallacy"}

*if: randomNumber = 118
	*group
		>> bias = {"name" -> "Etymological Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The Etymological Fallacy is a genetic fallacy that holds, erroneously, that the historical meaning of a word or phrase is necessarily similar to (or can be used to clarify) its actual present-day meaning.<br><br>&quot;Knave is really not such an insult, since originally it just meant 'boy'.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/etymological_fallacy", "groupName" -> "EtymologicalFallacy"}

*if: randomNumber = 119
	*group
		>> bias = {"name" -> "Fallacy of Composition", "content" -> "<div class='text' style='font-size: 16.8px;'>Inferring that something is true of the whole from the fact that it is true of some part of the whole (or even of every proper part)<br><br>&quot;Most individual Americans would be better off if they saved a lot more money. Therefore, if everyone saved a lot more money, we would all be better off.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/fallacy_of_composition", "groupName" -> "FallacyOfComposition"}

*if: randomNumber = 120
	*group
		>> bias = {"name" -> "Fallacy of False Dilemma", "content" -> "<div class='text' style='font-size: 16.8px;'>Involves a situation in which only two alternatives are considered, when in fact there are additional options.<br><br>&quot;Either you are with us, or you are with the terrorists.&quot;<br>&quot;You are either a nice guy, or a not nice guy. Which is it?&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/false_dilemma", "groupName" -> "FallacyOfFalseDilemma"}

*if: randomNumber = 121
	*group
		>> bias = {"name" -> "If-by-whiskey Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The response to a question or definitions used is contingent on the questioner's opinions and the use of words with strong positive or negative connotations.<br><br>&quot;If when you say whiskey you mean the devil's brew, the poison scourge, the bloody monster that defiles innocence...then certainly I am against it. But, if when you say whiskey you mean the oil of conversation, the philosophic wine, the ale that is consumed when good fellows get together...then certainly I am for it.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/if-by-whiskey", "groupName" -> "IfbywhiskeyFallacy"}

*if: randomNumber = 122
	*group
		>> bias = {"name" -> "Loaded Question Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>A question which contains a controversial assumption such as a presumption of guilt.<br><br>&quot;We have heard that a half million children have died due to U.S. sanctions against Iraq. Is the price worth it?&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/loaded_question", "groupName" -> "LoadedQuestionFallacy"}

*if: randomNumber = 123
	*group
		>> bias = {"name" -> "Ludic Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that your model for something captures all aspects, and all risks associated with it, that is, that there are no unknown unknowns.</div><br>", "source" -> "http://en.wikipedia.org/wiki/ludic_fallacy", "groupName" -> "LudicFallacy"}

*if: randomNumber = 124
	*group
		>> bias = {"name" -> "Fallacy of the Single Cause", "content" -> "<div class='text' style='font-size: 16.8px;'>Occurs when it is assumed that there is a single, simple cause of an outcome, when in reality it may have been caused by a number of only jointly sufficient causes.<br><br>&quot;Was this school shooting caused by violence in video games, or by poor parenting?&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/fallacy_of_the_single_cause", "groupName" -> "FallacyOfTheSingleCause"}

*if: randomNumber = 125
	*group
		>> bias = {"name" -> "Historian's Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Occurs when one assumes that decision makers of the past viewed events from the same perspective, and had the same information as those subsequently analyzing the decision, or knew the significance of what they were doing.</div><br>", "source" -> "http://en.wikipedia.org/wiki/historian%27s_fallacy", "groupName" -> "HistoriansFallacy"}

*if: randomNumber = 126
	*group
		>> bias = {"name" -> "Incomplete Comparison Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>A claim is made that does not contain complete information, and so cannot be refuted.<br><br>&quot;Our product is longer lasting!&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/incomplete_comparison", "groupName" -> "IncompleteComparisonFallacy"}

*if: randomNumber = 127
	*group
		>> bias = {"name" -> "Inconsistent Comparison Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Various items are compared along differing dimensions in such a way that it gives the impression that one item is superior.<br> <br>&quot;Product X is less expensive than product A, has better quality than product B, and has more features than product C.&quot;<br><br>All this really means though is that &quot;product X is not the most expensive, lowest quality, and fewest feature bearing product on the market.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/inconsistent_comparison", "groupName" -> "InconsistentComparisonFallacy"}

*if: randomNumber = 128
	*group
		>> bias = {"name" -> "Irrelevant Conclusion Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Presenting an argument that may in itself be valid, but does not address the issue in question.<br><br>&quot;Vanilla is the best ice cream.&quot; <br>&quot;No, chocolate is.&quot; <br>&quot;Well, I need more than chocolate. I believe that we need freedom, and choice when it comes to our ice-cream. That is the definition of liberty.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/ignoratio_elenchi", "groupName" -> "IrrelevantConclusionFallacy"}

*if: randomNumber = 129
	*group
		>> bias = {"name" -> "Moving the Goalposts Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Evidence presented in response to a specific claim is dismissed and some other (often greater) evidence is demanded. In other words, after an attempt has been made to score a goal, the goalposts are moved to exclude the attempt.<br><br>&quot;You may have shown that some of the predictions of evolutionary theory have come true, but unless you can show conclusively that all of them have come true, that means nothing.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/moving_the_goalposts", "groupName" -> "MovingTheGoalpostsFallacy"}

*if: randomNumber = 130
	*group
		>> bias = {"name" -> "Nirvana Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Comparing actual things with unrealistic, idealized alternatives. It can also refer to the tendency to assume that there is a perfect solution to a particular problem.<br><br>&quot;These new school proposals are unacceptable, because some students will still not be getting sufficient attention from teachers.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/nirvana_fallacy", "groupName" -> "NirvanaFallacy"}

*if: randomNumber = 131
	*group
		>> bias = {"name" -> "&quot;After This, Therefore Because of This&quot; Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assumes that because one thing came after another, the first must have caused the second.<br><br>&quot;My child became autistic right after she got her vaccine, so the vaccine must have caused it.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/post_hoc_ergo_propter_hoc", "groupName" -> "&quotafterThisThereforeBecauseOfThisquotFallacy"}

*if: randomNumber = 132
	*group
		>> bias = {"name" -> "Perfectionist Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that the only option on the table is perfect success, then rejecting anything that will not work perfectly.<br><br>&quot;What's the point of these anti-drunk driving ad campaigns? People are still going to drink and drive no matter what.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "PerfectionistFallacy"}

*if: randomNumber = 133
	*group
		>> bias = {"name" -> "Prosecutor's Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Fallacy of statistical reasoning made in law where the context in which the accused has been brought to court is falsely assumed to be irrelevant to judging how confident a jury can be in evidence against them. For example, if the defendant was selected from a large group because of the evidence under consideration, then this fact should be included in weighing how incriminating that evidence is.<br><br>&quot;The probability of finding this evidence if the accused were innocent is tiny, so the accused must be guilty.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/prosecutor%27s_fallacy", "groupName" -> "ProsecutorsFallacy"}

*if: randomNumber = 134
	*group
		>> bias = {"name" -> "Red Herring fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Introducing irrelevant material to the argument to distract and lead towards a different conclusion. <br><br>&quot;Why should the senator account for irregularities in his expenses? After all, there are senators who have done far worse things.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "RedHerringFallacy"}

*if: randomNumber = 135
	*group
		>> bias = {"name" -> "Retrospective Determinism Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that because something happened, it was therefore bound to happen.<br><br>&quot;The kings assassination proves that, sooner or later, he was bound to be killed by his enemies.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/retrospective_determinism", "groupName" -> "RetrospectiveDeterminismFallacy"}

*if: randomNumber = 136
	*group
		>> bias = {"name" -> "Slippery Slope Argument", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming a relatively small first step will inevitably lead to a chain of related (negative) events .<br><br>&quot;If we legalize marijuana, more people will start using crack and heroin. Then we'd have to legalize those too.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "SlipperySlopeArgument"}

*if: randomNumber = 137
	*group
		>> bias = {"name" -> "No True Scotsman Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>When faced with a counterexample to a universal claim, rather than denying the counterexample or rejecting the original universal claim, this fallacy modifies the subject of the assertion or their definition to exclude the specific case or others like it.<br><br>&quot;No Scotsman would do such a thing.&quot; &quot;But a Scotsman just did!&quot; &quot;No TRUE Scotsman would do such a thing.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/no_true_scotsman", "groupName" -> "NoTrueScotsmanFallacy"}

*if: randomNumber = 138
	*group
		>> bias = {"name" -> "Cherry Picking Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>The act of pointing to individual cases or data that seem to confirm a particular position, while ignoring a significant portion of related cases or data that may contradict that position.<br><br>&quot;Most college students don't have jobs during college.&quot; &quot;Oh yeah? Well, almost every one of my best friends in college had a job.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/cherry_picking_(fallacy)", "groupName" -> "CherryPickingFallacy"}

*if: randomNumber = 139
	*group
		>> bias = {"name" -> "False Analogy Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>A and B are similar in some ways. A has property X, therefore B has property X.<br><br>&quot;Men and tigers both are angered by efforts to threaten their status. But we can learn from dealing with tigers how to deal with men, because tigers do not grow angry when female tigers threaten their status.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/false_analogy", "groupName" -> "FalseAnalogyFallacy"}

*if: randomNumber = 140
	*group
		>> bias = {"name" -> "Misleading Vividness Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that because an example is more vividly described, it is more likely to be representative or worth taking into account or lead to a true conclusion.<br><br>&quot;I wouldn't take up golf if I were you. Do you remember Charles? He was playing golf when he got hit by a golf cart. It broke his leg, and he fell over, giving himself a concussion. He was in hospital for a week and still walks with a limp.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/misleading_vividness", "groupName" -> "MisleadingVividnessFallacy"}

*if: randomNumber = 141
	*group
		>> bias = {"name" -> "Spotlight Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assumes that most members or cases of a certain class or type are like those that receive the most attention or coverage in the media.<br><br>&quot;Most therapists just sit there and listen to you, or insist on asking you questions about your feelings about your parents.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/spotlight_fallacy", "groupName" -> "SpotlightFallacy"}

*if: randomNumber = 142
	*group
		>> bias = {"name" -> "Thought Terminating Clich√©", "content" -> "<div class='text' style='font-size: 16.8px;'>A saying that is used to get you or others to stop thinking something through.<br><br>&quot;We each make sacrifices for the greater good.&quot;<br><br>&quot;Dear leader knows best.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/thought-terminating_clich=e9#thought-terminating_clich.c3.a9", "groupName" -> "ThoughtTerminatingClich"}

*if: randomNumber = 143
	*group
		>> bias = {"name" -> "Ad Hominem Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Attacking the arguer instead of the argument in order to draw the conclusion that the argument is false.<br><br>&quot;He was a Nazi! We can't trust his research on the gallbladder.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/ad_hominem", "groupName" -> "AdHominemFallacy"}

*if: randomNumber = 144
	*group
		>> bias = {"name" -> "Appeal to the People Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that because something is widely believed, it is likely to be true.<br><br>&quot;Everyone knows that bats are blind.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/argumentum_ad_populum", "groupName" -> "AppealToThePeopleFallacy"}

*if: randomNumber = 145
	*group
		>> bias = {"name" -> "Appeal to Authority Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Arguing that a statement is correct because the statement is made by a person or source that is commonly regarded as authoritative.<br><br>Source A says that P is true. <br>Source A is authoritative. <br>Therefore, P is true.<br><br>&quot;As Samuel Johnson said, patriotism is the last refuge of the scoundrel.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/appeal_to_authority", "groupName" -> "AppealToAuthorityFallacy"}

*if: randomNumber = 146
	*group
		>> bias = {"name" -> "Appeal to common practice fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Claiming something is true because it's commonly practiced.<br><br>&quot;This bank has some problems with corruption. But there's nothing going on here that doesn't go on in all the other banks.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AppealToCommonPracticeFallacy"}

*if: randomNumber = 147
	*group
		>> bias = {"name" -> "Appeal to Consequences Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>An argument that concludes a premise (typically a belief) to be either true or false based on whether the premise leads to desirable or undesirable consequences.<br><br>&quot;You're theory cannot possibly be true, as if it were, our lives would be meaningless.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/appeal_to_consequences", "groupName" -> "AppealToConsequencesFallacy"}

*if: randomNumber = 148
	*group
		>> bias = {"name" -> "Appeal to Fear Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Arguing that one of two things has to be true, but because one of them is frightening, this makes the person want to believe the other.<br><br>Either P or Q is true. <br>Q is frightening. <br>Therefore, P is true.<br> <br>&quot;You have to study harder, because if you cannot graduate from high school, you will live in poverty for the rest of your life.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/appeal_to_fear", "groupName" -> "AppealToFearFallacy"}

*if: randomNumber = 149
	*group
		>> bias = {"name" -> "Appeal to Flattery Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Using an irrelevant compliment to slip in an unfounded claim which is accepted along with the compliment.<br><br>&quot;Intelligent and sophisticated readers will of course recognize a fallacy like this when they read one.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AppealToFlatteryFallacy"}

*if: randomNumber = 150
	*group
		>> bias = {"name" -> "Appeal to Ridicule Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Casting an opponent's argument in a light that makes it sound silly or ridiculous in order to bolster a claim that it is false.<br><br>&quot;If Einstein's theory of relativity is right, that would mean that when I drive my car it gets shorter and more massive the faster I go. That's crazy!&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/appeal_to_ridicule", "groupName" -> "AppealToRidiculeFallacy"}

*if: randomNumber = 151
	*group
		>> bias = {"name" -> "Appeal to Motive Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Claiming an argument must be false because of biased motives of the person making it.<br><br>&quot;We can't trust the evidence that he produces, because he clearly wants his theory to be true.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/appeal_to_motive", "groupName" -> "AppealToMotiveFallacy"}

*if: randomNumber = 152
	*group
		>> bias = {"name" -> "Appeal to Nature Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Arguing that because something is natural it is good, or because it is unnatural it is bad.<br><br>&quot;Human beings were not designed to have sex with animals, therefore sex with animals is wrong.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/appeal_to_nature", "groupName" -> "AppealToNatureFallacy"}

*if: randomNumber = 153
	*group
		>> bias = {"name" -> "Appeal to Novelty Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Supposing something is better because it is new or newer.<br><br>&quot;Awesome! The latest version of this operating system is going to make my computer faster and better..&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AppealToNoveltyFallacy"}

*if: randomNumber = 154
	*group
		>> bias = {"name" -> "Appeal to Pity Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Attempt to induce pity to sway opponents.<br><br>The former dictator is an old, dying man. It's wrong to make him stand trial for these alleged offenses.</div><br>", "source" -> "rhetological", "groupName" -> "AppealToPityFallacy"}

*if: randomNumber = 155
	*group
		>> bias = {"name" -> "Appeal to Popular Belief Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Claiming something is true because the majority of people believe it.<br><br>&quot;Milk is essential for healthier bones&quot;</div><br>", "source" -> "rhetological", "groupName" -> "AppealToPopularBeliefFallacy"}

*if: randomNumber = 156
	*group
		>> bias = {"name" -> "Chronological Snobbery Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that because something used to be believed in a time when many stupid or naive things were believed, that implies it is false.<br><br>&quot;There is no way that head size correlates with intelligence. That's the sort of dumb theory people used to believe hundreds of years ago when they were practicing phrenology!&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/chronological_snobbery", "groupName" -> "ChronologicalSnobberyFallacy"}

*if: randomNumber = 157
	*group
		>> bias = {"name" -> "Genetic Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that the origins of something determine its current significance or meaning now.<br><br>&quot;You're not going to wear a wedding ring, are you? Don't you know that the wedding ring originally symbolized ankle chains worn by women to prevent them from running away from their husbands?&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/genetic_fallacy", "groupName" -> "GeneticFallacy"}

*if: randomNumber = 158
	*group
		>> bias = {"name" -> "Guilt by Association", "content" -> "<div class='text' style='font-size: 16.8px;'>Discrediting an idea or claim by associating it with an undesirable person or group.<br><br>&quot;&quot;Oh you want to relax the anti-terrorism laws just like the terrorists want us to do. Are you saying you support terrorism?&quot;&quot;</div><br>", "source" -> "rhetological", "groupName" -> "GuiltByAssociation"}

*if: randomNumber = 159
	*group
		>> bias = {"name" -> "Hasty Generalization", "content" -> "<div class='text' style='font-size: 16.8px;'>Drawing a general conclusion from a tiny sample.<br><br>&quot;I just got cut up by the woman driver in front. Women can't drive.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "HastyGeneralization"}

*if: randomNumber = 160
	*group
		>> bias = {"name" -> "Straw Man Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Attempting to win an argument by refuting an easier to handle version of the opponent's position that they don't actually believe.<br><br>&quot;Scientists are saying that the universe started in a massive explosion. But, at the beginning, how can you have an explosion? There is nothing there to explode.&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/straw_man", "groupName" -> "StrawManFallacy"}

*if: randomNumber = 161
	*group
		>> bias = {"name" -> "Suppressed Evidence Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Intentionally failing to use significant and relevant information which counts against one‚Äôs own conclusion.<br><br>&quot;This Iraqi regime possesses and produces chemical and biological weapons. It is seeking nuclear weapons.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "SuppressedEvidenceFallacy"}

*if: randomNumber = 162
	*group
		>> bias = {"name" -> "Two Wrongs Make a Right Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Assuming that if one wrong is committed, another wrong will cancel it out.<br><br>&quot;Sure - the conditions in this prison are cruel and dehumanizing. But these inmates are criminals!&quot;</div><br>", "source" -> "rhetological", "groupName" -> "TwoWrongsMakeARightFallacy"}

*if: randomNumber = 163
	*group
		>> bias = {"name" -> "Unfalsifiable Claim", "content" -> "<div class='text' style='font-size: 16.8px;'>Offering a claim that cannot be proven false, because there is no way to check if it is false or not. <br><br>&quot;He lied because he‚Äôs possessed by demons.&quot;</div><br>", "source" -> "rhetological", "groupName" -> "UnfalsifiableClaim"}

*if: randomNumber = 164
	*group
		>> bias = {"name" -> "Appeal to Hypocrisy Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>Arguing that a position is wrong, because the person arguing for it does not live in accordance with it.<br><br>&quot;He says lying is wrong. But look at him! He's been known to lie himself!&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/tu_quoque", "groupName" -> "AppealToHypocrisyFallacy"}

*if: randomNumber = 165
	*group
		>> bias = {"name" -> "Typical Mind Fallacy", "content" -> "<div class='text' style='font-size: 16.8px;'>There was a debate, in the late 1800s, about whether &quot;imagination&quot; was simply a turn of phrase or a real phenomenon. That is, can people actually create images in their minds which they see vividly, or do they simply say &quot;I saw it in my mind&quot; as a metaphor for considering what it looked like?<br><br>The debate was resolved by Francis Galton, who among other achievements invented eugenics, the &quot;wisdom of crowds&quot;, and standard deviation. Galton gave people some very detailed surveys, and found that some people did have mental imagery and others did not. The ones who did simply assumed everyone did, and the ones who didn't simply assumed everyone didn't, to the point of coming up with absurd justifications for why they were lying or misunderstanding the question. There was a wide spectrum of imaging ability, from about five percent of people with perfect eidetic imagery to three percent of people completely unable to form mental images.</div><br>", "source" -> "http://lesswrong.com/lw/dr/generalizing_from_one_example/", "groupName" -> "TypicalMindFallacy"}

*if: randomNumber = 166
	*group
		>> bias = {"name" -> "Fallacy of Grey / Gray", "content" -> "<div class='text' style='font-size: 16.8px;'> The Sophisticate: &quot;The world isn't black and white. No one does pure good or pure bad. It's all gray. Therefore, no one is better than anyone else.&quot;<br> The Zetet: &quot;Knowing only gray, you conclude that all grays are the same shade. You mock the simplicity of the two-color view, yet you replace it with a one-color view...&quot;<br> ‚ÄîMarc Stiegler, David's Sling<br><br>Everything is shades of gray, but there are shades of gray so light as to be very nearly white, and shades of gray so dark as to be very nearly black. Or even if not, we can still compare shades, and say &quot;it is darker&quot; or &quot;it is lighter&quot;.<br><br>The Fallacy of Gray is a belief that because nothing is certain, everything is equally uncertain. One who commits this fallacy may reply to the statement that odds of two to the power of seven hundred and fifty million to one, against, meant &quot;there was still a chance&quot;.<br><br>This fallacy is invoked by those who wish to attack a well performing system (e.g. science), by saying that it is still imperfect. This then excuses the imperfections of the invoker's chosen system. For example &quot;Science is based on faith too!&quot;</div><br>", "source" -> "http://lesswrong.com/lw/mm/the_fallacy_of_gray/", "groupName" -> "FallacyOfGreyGray"}

*if: randomNumber = 167
	*group
		>> bias = {"name" -> "Change Bias in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>After an investment of effort in producing change, remembering one's past performance as more difficult than it actually was.</div><br>", "source" -> "Psychology", "groupName" -> "ChangeBiasInMemory"}

*if: randomNumber = 168
	*group
		>> bias = {"name" -> "Childhood Amnesia in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>The retention of few memories from before the age of four. This is a scarcity that cannot be accounted for by a forgetting curve. Additionally, the boundary is malleable and can be influenced by both<br>individual experiences and cultural factors.<br><br>It has been suggested that the average age of the first memories is three years, six months, with the vast majority of subjects dating their first recollection somewhere between ages two and five years. Very few memories of adults precede 30 months, and those that are reported at this time show considerable confabulation with individuals unable to tell the difference between a memory of an event and simple knowledge of the event (i.e. gained from discussion by others).</div><br>", "source" -> "http://en.wikipedia.org/wiki/Childhood_amnesia", "groupName" -> "ChildhoodAmnesiaInMemory"}

*if: randomNumber = 169
	*group
		>> bias = {"name" -> "Context Effect in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>That cognition and memory are dependent on context, such that out-of-context memories are more difficult to retrieve than in-context memories (e.g., recall time and accuracy for a work-related memory will be lower at home, and vice versa)<br><br>Context-dependent cues are dependent on the environment and situation. Memory retrieval can be facilitated or triggered by replication of the context in which the memory was encoded. Such conditions include weather, company, location, smelling of a particular odor, hearing a certain song, even taste can sometimes act as a cue. For example, students sometimes fail to recall diligently studied material when an examination room's environmental conditions differ significantly from the room or place where learning occurred. To improve learning and recall, it is recommended that students should study under conditions that closely resemble an examination. Psychologists that have researched context dependent recall include Abernathy (1940), as well as Godden & Baddeley (1975).</div><br>", "source" -> "http://en.wikipedia.org/wiki/Context-dependent_memory", "groupName" -> "ContextEffectInMemory"}

*if: randomNumber = 170
	*group
		>> bias = {"name" -> "Fading Affect Bias in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>A bias in which the emotion associated with unpleasant memories fades more quickly than the emotion associated with positive events.<br><br>&quot;Life Is Pleasant - and Memory Helps to Keep It That Way!&quot;</div><br>", "source" -> "http://en.wikipedia.org/wiki/List_of_memory_biases", "groupName" -> "FadingAffectBiasInMemory"}

*if: randomNumber = 171
	*group
		>> bias = {"name" -> "Hindsight Bias in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>Hindsight Bias is the inclination to see events that have already occurred as being more predictable than they were before they took place<br><br>Beyth and Fischoff devised the first experiment directly testing the hindsight bias. They asked participants to judge the likelihood of several outcomes of President Nixon's upcoming visit to Peking (also known as Beijing) and Moscow. Some time after President Nixon's return, participants were asked to recall, or reconstruct the probabilities they had assigned to each possible outcome, and their perceptions of likelihood of each outcome was greater or overestimated for events that actually had occurred.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Hindsight", "groupName" -> "HindsightBiasInMemory"}

*if: randomNumber = 172
	*group
		>> bias = {"name" -> "Humor Effect in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>That humorous items are more easily remembered than non-humorous ones, which might be explained by the distinctiveness of humor, the increased cognitive processing time to understand the humor, or the emotional arousal caused by the humor.</div><br>", "source" -> "http://en.wikipedia.org/wiki/List_of_memory_biases", "groupName" -> "HumorEffectInMemory"}

*if: randomNumber = 173
	*group
		>> bias = {"name" -> "(Self) Generation Effect in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>The Generation Effect refers to the robust finding that information will be better remembered if it is generated rather than simply read. For example, you are more likely to remember the word &quot;orangutan&quot; if you generate it from the fragment &quot;or_ng_ta_&quot; than if you simply see the word in its entirety.<br><br>The Generation Effect is usually achieved in cognitive psychology experiments where participants are asked to generate words from word fragments. It has also been demonstrated using a variety of other materials, such as when generating a word after being presented with its antonym or synonym, or generating keywords in paragraphs, pictures, and arithmetic problems. In addition, the generation effect has been found in studies using free recall, cued recall, and recognition tests.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Generation_effect", "groupName" -> "(selfGenerationEffectInMemory"}

*if: randomNumber = 174
	*group
		>> bias = {"name" -> "Accuracy of our Memories of our Emotional Responses", "content" -> "<div class='text' style='font-size: 16.8px;'>Oddly, we don't seem to learn all that much from our own experience. To learn from experience requires that we be able to remember it, and research shows that people are about as bad at remembering their past emotions as they are predicting their future emotions. That's why we make the same errors again and again. For example, in one of our studies, Democrats predicted they'd be devastated if Bush won the 2004 presidential election, and as we always find, they were not nearly as devastated as they predicted. But several months after the election, they remembered being just as devastated as they had expected to be. It turns out that this is a very common pattern of memory errors. Retrospection and prospection share many of the same biases, and hence reinforce each other.</div><br>", "source" -> "http://www.randomhouse.com/kvpa/gilbert/qa.html", "groupName" -> "AccuracyOfOurMemoriesOfOurEmotionalResponses"}

*if: randomNumber = 175
	*group
		>> bias = {"name" -> "Illusion-of-truth Memory Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>People are more likely to identify as true statements those they have previously heard (even if they cannot consciously remember having heard them), regardless of the actual validity of the statement. In other words, a person is more likely to believe a familiar statement than an unfamiliar one.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Implicit_memory#Illusion-of-truth_effect", "groupName" -> "IllusionoftruthMemoryBias"}

*if: randomNumber = 176
	*group
		>> bias = {"name" -> "Mood-congruent Memory Bias", "content" -> "<div class='text' style='font-size: 16.8px;'>The improved recall of information congruent with one's current mood.</div><br>", "source" -> "http://en.wikipedia.org/wiki/List_of_memory_biases", "groupName" -> "MoodcongruentMemoryBias"}

*if: randomNumber = 177
	*group
		>> bias = {"name" -> "Next-in-line Effect in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>That a person in a group has diminished recall for the words of others who spoke immediately before or after this person.</div><br>", "source" -> "http://en.wikipedia.org/wiki/List_of_memory_biases", "groupName" -> "NextinlineEffectInMemory"}

*if: randomNumber = 178
	*group
		>> bias = {"name" -> "Part-set Cueing Effect in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>Presenting a subset of previously learned items as retrieval &quot;cues&quot; often impairs recall for the remaining information. (Roediger, 1973)<br><br>However, relearning part of a set of previously learned associations can improve recall of the non-relearned associations.</div><br>", "source" -> "Slamecka", "groupName" -> "PartsetCueingEffectInMemory"}

*if: randomNumber = 179
	*group
		>> bias = {"name" -> "Rosy Retrospection in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>Rosy Retrospection refers to the finding that subjects later rate past events more positively than they had actually rated them when the event occurred; reminiscent of the Latin phrase &quot;memoria praeteritorum bonorum&quot; (&quot;the past is always recalled to be good&quot;).<br><br>The effect appears to be stronger with moderately pleasant events and is usually explained as a result of minor annoyances and dislikes &quot;fading&quot; from memory dramatically faster than positive situations.<br><br>Reference class forecasting (the method of predicting the future, through looking at similar past situations and their outcomes) was developed to eliminate or reduce the effect of rosy retrospection in decision making.</div><br>", "source" -> "http://en.wikipedia.org/wiki/Rosy_retrospection", "groupName" -> "RosyRetrospectionInMemory"}

*if: randomNumber = 180
	*group
		>> bias = {"name" -> "Telescoping Effect in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>People's tendency to perceive recent events as being more remote than they are, and to perceive distant events as being more recent than they are. More specifically, the former is known as &quot;backward telescoping&quot;, and the latter as &quot;forward telescoping&quot;. Between backward and forward telescoping there lies a point at which events are just as likely to be displaced backward as forward in time.<br><br>The original work is usually attributed to a 1964 article by Neter and Waksberg in the Journal of the American Statistical Association.</div><br>", "source" -> "http://www2.fiu.edu/~dwright/pdf/telescopepoq.pdf", "groupName" -> "TelescopingEffectInMemory"}

*if: randomNumber = 181
	*group
		>> bias = {"name" -> "Zeigarnik Effect in Memory", "content" -> "<div class='text' style='font-size: 16.8px;'>States that people remember uncompleted or interrupted tasks better than completed tasks.<br><br>Soviet psychologist Bluma Zeigarnik first studied the phenomenon after her professor, Gestalt psychologist Kurt Lewin, noticed that a waiter had better recollections of still unpaid orders.<br><br>In Gestalt psychology, the Zeigarnik effect has been used to demonstrate the general presence of Gestalt phenomena: not just appearing as perceptual effects, but also present in cognition.<br><br>The Zeigarnik effect suggests that students who &quot;suspend&quot; their study, during which they do unrelated activities (such as studying unrelated subjects or playing games), will remember material better than students who complete study sessions without a break (Zeigarnik, 1927; McKinney 1935).</div><br>", "source" -> "http://www.psychwiki.com/wiki/Zeigarnik_Effect", "groupName" -> "ZeigarnikEffectInMemory"}


---------------
-- QUESTIONS --
---------------

*page

	-----------------
	-- QUESTION #1 --
	-----------------

	*html
		<h1 class="alert alert-info"><b>Bias:</b> {bias["name"]}</h1>

	*html
		{bias["content"]}

	If you want, you can read more about the {bias["name"]} [here|{bias["source"]}].

	*html
		<hr>

	*html
		<h1 class="alert alert-danger">Question #1</h1>

	*question: Imagine a scenario in which you're trying to help a friend or loved one to adopt a new positive habit or pattern of behavior, like going to the gym regularly, giving to charity each month, managing anger, meditating every morning, etc. If your friend or loved one was having trouble adopting the new habit or behavior because they were getting tripped up by the {bias["name"]}, then how would you help them to overcome that bias and adopt the new habit or behavior? Or if you could ethically leverage the {bias["name"]} to help the person to adopt the new habit or behavior, then how would you do it? Think: "To help a friend or loved one to overcome the {bias["name"]} and adopt a new positive habit or pattern of behavior, I would _____." Or, conversely (or additionally): "To ethically leverage the {bias["name"]} to help someone to adopt a new positive habit or pattern of behavior, I would _____." Please provide as much detail as you can!
		*tip: If you think about it for a while and can't imagine a way in which the {bias["name"]} has anything to do with adopting a new habit or behavior, then feel free to write something like "New behavior adoption isn't affected by this bias" in the answer box below.
		*type: paragraph
		*save: temp1

	-----------------
	-- QUESTION #2 --
	-----------------

	*html
		<hr>

	*html
		<h1 class="alert alert-danger">Question #2</h1>

	*question: The *Ten Conditions for Change* is a framework for helping people to adopt new positive behaviors or habits. The framework basically claims that if people have met all ten conditions, then they will adopt a new behavior. Given the definitions of the Ten Conditions for Change below and the definition of the {bias["name"]}, which of the Ten Conditions do you think is *most* affected by the {bias["name"]}? In other words, if a person is trying to adopt a new positive behavior but is failing to do so because they're suffering from the {bias["name"]}, then which of the Ten Conditions are they likely failing to meet? Or, conversely, if you could ethically leverage the {bias["name"]} to help someone adopt a new behavior, then which of the Ten Conditions would you most affect by leveraging the bias? (If you want, you can read more about the Ten Conditions for change [here|https://www.sparkwave.tech/conditions-for-change/].)
		*save: temp2
		1. A person *considers* the behavior. A person is very unlikely to change a behavior if they have not even considered changing it.
		2. A person *desires* to adopt the new behavior. Even if a person has considered adopting a new behavior, they're very unlikely to actually do so unless they desire to adopt it. There are two different types of desire: /intuitive desire/ (a gut-level positive feeling or emotion about engaging in a behavior) and /reflective desire/ (an analytical, reasoned belief that the behavior is worthwhile). To make a behavior likely, it's critical to have at least one of these two forms of desires, but it's best if the person desires the behavior in both the intuitive and reflective senses.
		3. A person *intends* to adopt the new behavior. Even if a person desires to adopt a new behavior, they're very unlikely to actually do so unless they themselves predict that they will conduct that behavior at specific times, in specific situations, or within a certain time frame.
		4. A person *remembers* to perform the actions that make up the new behavior. A person is unlikely to adopt a new behavior if they don't remember to perform the relevant actions at the right times.
		5. A person *believes* (1) that the relevant actions have a significant connection to the adoption of the new behavior and (2) that they themselves are able to perform the actions. A person is very unlikely to attempt a specific action if they don't think that attempting it will help them to achieve the desired outcome.
		6. A person *chooses* to perform the relevant actions instead of performing other actions. Even if a person remembers to perform an action, they're very unlikely to perform that action unless they choose it over the other actions or opportunities that are available to them at the same time.
		7. A person *knows* how to perform each action. A person is very unlikely to perform a specific action unless they have the information or knowledge needed to perform that action effectively.
		8. A person *has* the necessary resources and permission to perform the relevant actions. A person is very unlikely to perform a specific action unless they have the resources or permissions they need to perform that action effectively.
		9. A person *embodies* the skills and traits needed to perform the relevant actions. A person is very unlikely to perform a specific action unless they have the physical capacities, mental capabilities, and skills needed to perform that action.
		10. A person *maintains* all of the things needed to perform the relevant actions in the future. A person is very unlikely to perform future required actions if, due to the experience of taking earlier actions or due to the passage of time, the conditions mentioned above fall below adequate levels.
		None of the above. This bias doesn't affect any of the above conditions.

>> final["{bias["name"]}: Question #1"] = temp1
>> final["{bias["name"]}: Question #2"] = temp2
>> counter = counter + 1

*if: counter <= 3
	*goto: randomizer

---------
-- END --
---------

*header: Thanks!

Thank you so much for your time and effort! We really appreciate your participation! Follow the link below to finish up and get paid!

*component
	*classes: alert alert-danger
	*NOTE* *:* We've been notified that there's a problem with the feedback survey that you'll complete after this activity. We're looking into it right now and will hopefully have it fixed soon. In the meantime, feel free to send us your feedback via a message. Thanks for your understanding and patience!

[https://app.positly.com/#/f?task_id=695e0c0f|https://app.positly.com/#/f?task_id=695e0c0f]